"""
AI Foundry Agent Creator
A Streamlit app to create Azure AI Foundry agents with Azure AI Search integration.
"""

# run the code with:  python -m streamlit run streamlit_app.py
import streamlit as st
import os
import subprocess
import json
import logging
import time
import traceback
from typing import Optional

from azure.identity import AzureCliCredential


logging.basicConfig(level=logging.DEBUG,
                    format="%(levelname)s | %(message)s")

# ---------- dynamic preview‚ÄëSDK import (resources / projects) ----------

AIProjectClient: Optional[object] = None
AgentsClient:    Optional[object] = None

# --- 1) quick, direct import paths ------------------------------------
try:                                   # new preview
    from azure.ai.resources import AIProjectClient  # type: ignore
except ModuleNotFoundError:
    try:                               # legacy preview
        from azure.ai.projects import AIProjectClient  # type: ignore
    except ModuleNotFoundError:
        pass

try:                                   # most preview builds expose this
    from azure.ai.agents import AgentsClient  # type: ignore
except ModuleNotFoundError:
    pass
# ----------------------------------------------------------------------

# --- 2) dynamic fallback for exotic wheel layouts ---------------------
if AIProjectClient is None or AgentsClient is None:
    from importlib import import_module

    def _load_class(base_pkg: str,
                    names: tuple[str, ...],
                    subs: tuple[str, ...] = ()) -> Optional[object]:
        """Try to load any of *class_names* from base_pkg or its sub‚Äëmodules."""
        try:
            pkg = import_module(base_pkg)
        except ModuleNotFoundError:
            return None
        for name in names:
            if hasattr(pkg, name):
                return getattr(pkg, name)
        for sub in subs:
            try:
                mod = import_module(f"{base_pkg}.{sub}")
                for name in names:
                    if hasattr(mod, name):
                        return getattr(mod, name)
            except ModuleNotFoundError:
                continue
        return None

    if AIProjectClient is None:
        for pkg in ("azure.ai.resources", "azure.ai.projects"):
            AIProjectClient = _load_class(pkg,
                                          ("AIProjectClient", "ProjectClient", "ProjectsClient"),
                                          ("_client", "client", "projects_client"))
            if AIProjectClient:
                break

    if AgentsClient is None:
        for pkg in ("azure.ai.agents", "azure.ai.resources"):
            AgentsClient = _load_class(pkg,
                                       ("AgentsClient", "AgentClient"),
                                       ("_client", "client"))
            if AgentsClient:
                break
# ----------------------------------------------------------------------

missing = []
if AIProjectClient is None:
    missing.append("azure-ai-resources | azure-ai-projects")
if AgentsClient is None:
    missing.append("azure-ai-agents")

if missing:
    st.error(
        "‚ö†Ô∏è  Required preview SDK(s) not detected:\n"
        "‚Ä¢ " + "\n‚Ä¢ ".join(missing) +
        "\n\nInstall preview wheels:\n"
        "```bash\n"
        "pip install --upgrade --pre azure-ai-resources azure-ai-projects "
        "azure-ai-agents\n"
        "```"
    )
    st.stop()
# ----------------------------------------------------------------------

from azure.ai.agents.models import AzureAISearchTool, AzureAISearchQueryType, BingGroundingTool
from azure.mgmt.resource import ResourceManagementClient
from azure.search.documents.indexes import SearchIndexClient
from azure.core.credentials import AzureKeyCredential

# Page config
st.set_page_config(
    page_title="AI Foundry Agent Creator",
    page_icon="ü§ñ",
    layout="wide"
)

# ----------------------------- Helpers --------------------------------

if "authenticated" not in st.session_state:
    st.session_state.authenticated = False
if "projects" not in st.session_state:
    st.session_state.projects = []
if "search_services" not in st.session_state:
    st.session_state.search_services = []
if "model_deployments" not in st.session_state:
    st.session_state.model_deployments = []

def check_azure_cli_login():
    """Check if the user is logged in via Azure CLI."""
    try:
        res = subprocess.run(["az", "account", "show"],
                             capture_output=True, text=True)
        if res.returncode == 0:
            return True, json.loads(res.stdout)
        return False, None
    except Exception:
        return False, None

def get_ai_foundry_projects(credential):
    """Return a list of AI Foundry projects the user can access."""
    projects: list[dict] = []
    try:
        sub = subprocess.run(
            ["az", "account", "show", "--query", "id", "-o", "tsv"],
            capture_output=True, text=True, check=True
        ).stdout.strip()

        resource_client = ResourceManagementClient(credential, sub)

        # Look for AI Studio/Foundry hubs (AIServices accounts)
        for resource in resource_client.resources.list(
                filter="resourceType eq 'Microsoft.CognitiveServices/accounts'"):
            
            # Skip non-AI Studio resources
            if resource.kind and resource.kind not in ['AIServices', 'Hub']:
                logging.debug(f"Skipping {resource.name} - kind: {resource.kind}")
                continue
                
            logging.debug(f"Found AI Services resource: {resource.name} (kind: {resource.kind})")
            
            base_endpoint = f"https://{resource.name}.services.ai.azure.com"
            
            # Try to list actual projects from this hub
            actual_projects = []
            try:
                # First try: connect to the hub and list projects
                hub_client = AIProjectClient(endpoint=base_endpoint, credential=credential)
                if hasattr(hub_client, 'projects') and hasattr(hub_client.projects, 'list'):
                    actual_projects = list(hub_client.projects.list())
                    logging.debug(f"Found {len(actual_projects)} projects in {resource.name}")
            except Exception as e:
                logging.debug(f"Could not list projects from hub: {e}")
            
            # If no projects found, try the default pattern
            if not actual_projects:
                # Default project name pattern
                default_project = f"{resource.name}-project"
                project_endpoint = f"{base_endpoint}/api/projects/{default_project}"
                
                # Verify if this default project exists
                try:
                    test_client = AIProjectClient(endpoint=project_endpoint, credential=credential)
                    # Quick test - try to get connections
                    test_client.connections.list()
                    # If we get here, project exists
                    actual_projects = [{"name": default_project, "verified": True}]
                    logging.debug(f"‚úì Default project exists: {default_project}")
                except Exception as e:
                    if "404" in str(e) or "NotFound" in str(e):
                        logging.debug("Default project 404 ‚Äì safe to ignore")
                    else:
                        logging.debug("Project existence uncertain ‚Äì continuing")
            
            # Add each found project
            for proj in actual_projects:
                project_name = proj.get("name", proj) if isinstance(proj, dict) else getattr(proj, "name", str(proj))
                project_endpoint = f"{base_endpoint}/api/projects/{project_name}"
                
                projects.append({
                    "name": project_name,
                    "resource_group": resource.id.split("/")[4],
                    "endpoint": project_endpoint,
                    "base_endpoint": base_endpoint,
                    "hub_name": resource.name,
                    "location": resource.location,
                    "id": resource.id,
                    "kind": resource.kind,
                    "verified": proj.get("verified", True) if isinstance(proj, dict) else True
                })

        if not projects:
            st.warning("No AI Foundry projects found. Create a project in Azure AI Studio first.")
            st.info("üí° Projects are created inside AI Hubs. Make sure you have at least one AI Hub with a project.")
    except Exception as e:
        st.error(f"Error fetching projects: {e}")
    return projects

def get_search_connections(project_endpoint, credential, account_id):
    """Return all Azure AI Search connections for a given project."""
    # clear any previous missing‚Äëpermission flag
    st.session_state.pop("permission_fix_scope", None)

    connections: list[dict] = []
    try:
        client = AIProjectClient(endpoint=project_endpoint, credential=credential)
        logging.debug(f"DEBUG ‚Ä¢ project_endpoint={project_endpoint}")
        
        # List all connections first
        all_connections = list(client.connections.list())
        logging.debug(f"Found {len(all_connections)} total connections")
        
        for conn in all_connections:
            # Log each connection for debugging
            conn_name = getattr(conn, "name", "unknown")
            conn_type = getattr(conn, "type", "unknown")
            
            # Properties might be nested differently
            props = {}
            if hasattr(conn, "properties"):
                props = conn.properties if isinstance(conn.properties, dict) else vars(conn.properties) if hasattr(conn.properties, '__dict__') else {}
            
            # Try different ways to get the endpoint
            target = props.get("target", "") or props.get("endpoint", "") or props.get("url", "")
            category = props.get("category", "")
            
            # Also check direct attributes
            if not target and hasattr(conn, "target"):
                target = conn.target
            if not target and hasattr(conn, "endpoint"):
                target = conn.endpoint
                
            logging.debug(f"Connection: {conn_name}, Type: {conn_type}, Category: {category}, Target: {target}")
            logging.debug(f"  Props keys: {list(props.keys()) if props else 'None'}")
            
            # Check if this is a search connection
            # Azure AI Search connections can have type "CognitiveSearch" or category "AzureCognitiveSearch"
            if any(term in str(conn_type).lower() for term in ["cognitivesearch", "search"]) or \
               any(term in str(category).lower() for term in ["search", "cognitivesearch"]) or \
               any(term in str(target).lower() for term in ["search.windows.net"]):
                
                # IMPORTANT: Build connection ID in Azure resource path format
                # Format: /subscriptions/{sub}/resourceGroups/{rg}/providers/Microsoft.CognitiveServices/accounts/{hub}/projects/{project}/connections/{connection}
                
                # Extract subscription ID from account_id (which is the hub resource ID)
                # account_id format: /subscriptions/{sub}/resourceGroups/{rg}/providers/Microsoft.CognitiveServices/accounts/{hub}
                hub_resource_parts = account_id.split('/')
                if len(hub_resource_parts) >= 8:
                    subscription_id = hub_resource_parts[2]
                    resource_group = hub_resource_parts[4]
                    hub_name = hub_resource_parts[8]
                    
                    # Extract project name from project_endpoint
                    # project_endpoint: https://{hub}.services.ai.azure.com/api/projects/{project}
                    project_name = project_endpoint.split('/api/projects/')[-1]
                    
                    # Build the full Azure resource path
                    conn_id = f"/subscriptions/{subscription_id}/resourceGroups/{resource_group}/providers/Microsoft.CognitiveServices/accounts/{hub_name}/projects/{project_name}/connections/{conn_name}"
                    
                    logging.info(f"‚úì Built Azure resource path connection ID: {conn_id}")
                else:
                    # Fallback to simpler format if we can't parse the hub resource ID
                    logging.warning(f"Could not parse hub resource ID: {account_id}")
                    conn_id = f"/projects/{project_endpoint.split('/')[-1]}/connections/{conn_name}"
                    logging.info(f"‚úì Using fallback connection ID: {conn_id}")
                
                # If we still don't have endpoint, try to construct it from connection name
                if not target and "search" in conn_name.lower():
                    # Sometimes the endpoint needs to be fetched separately
                    target = f"https://{conn_name}.search.windows.net"
                    
                connections.append({
                    "name": conn_name,
                    "id": conn_id,
                    "endpoint": target,
                    "category": category,
                    "type": conn_type,
                })
                logging.debug(f"‚úì Added search connection: {conn_name} with endpoint: {target}")
                
    except Exception as e:
        msg = str(e)
        st.error(f"Error fetching connections: {msg}")
        if "PermissionDenied" in msg and "connections/read" in msg:
            # remember the scope as the account_id
            st.session_state.permission_fix_scope = account_id
            st.warning("You don't have the **Azure AI User** role on this account. "
                       "Click the button below to grant it to yourself (requires Owner/Contributor rights).")
    
    if not connections:
        logging.debug("No search connections found after filtering")
        
    return connections

def get_model_deployments(project_endpoint, credential):
    """Return all model deployment names for the selected AI project."""
    deployments: list[str] = []
    try:
        client = AIProjectClient(endpoint=project_endpoint, credential=credential)
        # Azure AI Resources preview exposes .model_deployments or .deployments
        if hasattr(client, "model_deployments"):
            iterator = client.model_deployments.list()
        elif hasattr(client, "deployments"):
            iterator = client.deployments.list()
        else:
            iterator = []
        for dep in iterator:
            deployments.append(dep.name if hasattr(dep, "name") else str(dep))
    except Exception as e:
        st.error(f"Error fetching model deployments: {e}")
    return deployments

def get_search_indexes(search_endpoint, search_key=None, credential=None):
    """Get indexes from Azure AI Search service."""
    indexes: list[str] = []
    try:
        # Try with managed identity/credential first
        if credential and not search_key:
            from azure.search.documents.indexes import SearchIndexClient
            client = SearchIndexClient(
                endpoint=search_endpoint,
                credential=credential
            )
        elif search_key:
            # Fall back to key-based auth
            client = SearchIndexClient(
                endpoint=search_endpoint,
                credential=AzureKeyCredential(search_key)
            )
        else:
            return indexes
            
        indexes = [idx.name for idx in client.list_indexes()]
        logging.debug(f"Found {len(indexes)} indexes at {search_endpoint}")
    except Exception as e:
        logging.debug(f"Error fetching indexes: {e}")
    return indexes

def create_agent(project_endpoint, model_name, agent_name,
                 search_tool, instructions, credential, max_tokens=None):
    """Create an AI Foundry agent that uses Azure AI Search."""
    try:
        client = AgentsClient(endpoint=project_endpoint, credential=credential)
        
        # Debug: Log the search tool configuration
        logging.info(f"Creating agent with search tool:")
        logging.info(f"  Tool definitions: {search_tool.definitions}")
        logging.info(f"  Tool resources: {search_tool.resources}")
        
        # Add more detailed logging
        if 'azure_ai_search' in search_tool.resources:
            search_res = search_tool.resources['azure_ai_search']
            if 'indexes' in search_res and search_res['indexes']:
                idx = search_res['indexes'][0]
                logging.info(f"üìã Azure AI Search Configuration:")
                logging.info(f"  Connection ID: {idx.get('index_connection_id')}")
                logging.info(f"  Index Name: {idx.get('index_name')}")
                logging.info(f"  Query Type: {idx.get('query_type')}")
                logging.info(f"  Top K: {idx.get('top_k')}")
                
                # Validate the connection ID format
                conn_id = idx.get('index_connection_id', '')
                if conn_id.startswith('/subscriptions/'):
                    logging.info(f"‚úÖ Connection ID format is correct (Azure resource path)")
                elif conn_id.startswith('https://'):
                    logging.warning(f"‚ö†Ô∏è  Connection ID is in URL format, should be Azure resource path")
                else:
                    logging.warning(f"‚ö†Ô∏è  Connection ID format may be incorrect: {conn_id}")
                    logging.warning("   Expected format: /subscriptions/{sub}/resourceGroups/{rg}/providers/Microsoft.CognitiveServices/accounts/{hub}/projects/{project}/connections/{connection}")
        
        # Note: max_tokens parameter removed as it's not supported in current preview SDK
        agent = client.create_agent(
            name=agent_name,
            model=model_name,
            instructions=instructions,
            tools=search_tool.definitions,
            tool_resources=search_tool.resources,
        )
        
        # Debug: Log the created agent
        logging.info(f"‚úÖ Agent created successfully: {agent.id}")
        if hasattr(agent, 'tools'):
            logging.info(f"   Tools attached: {[str(tool) for tool in agent.tools]}")
        
        return True, agent.id
    except Exception as e:
        logging.error(f"‚ùå Error creating agent: {str(e)}")
        # Log more details about the error
        if "connection" in str(e).lower():
            logging.error("   This might be a connection ID format issue")
            logging.error("   Expected format: /subscriptions/{sub}/resourceGroups/{rg}/providers/Microsoft.CognitiveServices/accounts/{hub}/projects/{project}/connections/{connection}")
        return False, str(e)

def verify_agent_search_tool(agent_id, endpoint, credential):
    """Verify that the AI Search tool is properly attached to the agent."""
    try:
        client = AgentsClient(endpoint=endpoint, credential=credential)
        agent = client.get_agent(agent_id)
        
        verification_results = {
            "agent_found": True,
            "has_tools": False,
            "has_search_tool": False,
            "search_config": None,
            "details": {},
            "raw_tool_resources": None
        };
        
        # Check if agent has tools
        if hasattr(agent, 'tools') and agent.tools:
            verification_results["has_tools"] = True
            logging.info(f"‚úì Agent has {len(agent.tools)} tool(s)")
            
            # Check for AI Search tool
            for i, tool in enumerate(agent.tools):
                # Handle different tool representations
                if hasattr(tool, 'type'):
                    tool_type = tool.type
                elif isinstance(tool, dict):
                    tool_type = tool.get('type', 'unknown')
                else:
                    tool_type = str(tool)
                
                logging.info(f"  Tool {i+1}: type={tool_type}")
                
                if 'azure_ai_search' in str(tool_type).lower():
                    verification_results["has_search_tool"] = True
                    logging.info("‚úì Azure AI Search tool found!")
        
        # Check tool resources - handle different formats
        if hasattr(agent, 'tool_resources'):
            logging.info("Checking tool resources...")
            
            # Store raw tool resources for debugging
            if hasattr(agent.tool_resources, '__dict__'):
                verification_results["raw_tool_resources"] = vars(agent.tool_resources)
            else:
                verification_results["raw_tool_resources"] = str(agent.tool_resources)
            
            # Try different ways to access azure_ai_search
            search_resource = None
            
            # Method 1: Direct attribute
            if hasattr(agent.tool_resources, 'azure_ai_search'):
                search_resource = agent.tool_resources.azure_ai_search
                logging.info("Found azure_ai_search via direct attribute")
            
            # Method 2: Dictionary access
            elif hasattr(agent.tool_resources, '__getitem__'):
                try:
                    search_resource = agent.tool_resources['azure_ai_search']
                    logging.info("Found azure_ai_search via dictionary access")
                except (KeyError, TypeError):
                    pass
            
            # Method 3: Check if tool_resources is a dict
            elif isinstance(agent.tool_resources, dict):
                search_resource = agent.tool_resources.get('azure_ai_search')
                logging.info("Found azure_ai_search in dict")
            
            if search_resource:
                logging.info(f"Search resource type: {type(search_resource)}")
                
                # Log all attributes of search_resource for debugging
                if hasattr(search_resource, '__dict__'):
                    logging.info(f"Search resource attributes: {list(vars(search_resource).keys())}")
                
                # Try different ways to get indexes from AzureAISearchToolResource
                indexes = None
                
                # Method 1: Direct attribute access
                if hasattr(search_resource, 'indexes'):
                    indexes = search_resource.indexes
                    logging.info("Found indexes via direct attribute")
                
                # Method 2: Try underscore prefix (private attribute)
                elif hasattr(search_resource, '_indexes'):
                    indexes = search_resource._indexes
                    logging.info("Found indexes via _indexes")
                
                # Method 3: Access _data attribute if it exists
                elif hasattr(search_resource, '_data'):
                    data = search_resource._data
                    logging.info(f"Found _data attribute, type: {type(data)}")
                    
                    if isinstance(data, dict):
                        # Check for indexes in the data dictionary
                        if 'indexes' in data:
                            indexes = data['indexes']
                            logging.info("Found indexes in _data dictionary")
                            # Also log the structure of the first index for debugging
                            if indexes and len(indexes) > 0:
                                first_idx = indexes[0]
                                if hasattr(first_idx, '__dict__'):
                                    logging.info(f"First index attributes: {list(vars(first_idx).keys())}")
                                elif isinstance(first_idx, dict):
                                    logging.info(f"First index keys: {list(first_idx.keys())}")
                                else:
                                    logging.info(f"First index type: {type(first_idx)}, value: {first_idx}")
                        else:
                            logging.info(f"_data keys: {list(data.keys())}")
                    else:
                        logging.info(f"_data is not a dict, it's: {data}")
                
                # Process indexes if found
                if indexes:
                    logging.info(f"Found {len(indexes) if hasattr(indexes, '__len__') else '?'} index(es)")
                    
                    # Process first index
                    if hasattr(indexes, '__iter__') and len(indexes) > 0:
                        idx = indexes[0]
                        
                        # Try different ways to extract index details
                        idx_dict = {}
                        
                        # IMPORTANT: Check if the index object has a _data attribute
                        if hasattr(idx, '_data') and isinstance(idx._data, dict):
                            idx_dict = idx._data
                            logging.info(f"Found index data in _data: {list(idx_dict.keys())}")
                        # If it's an object with attributes
                        elif hasattr(idx, '__dict__'):
                            idx_dict = vars(idx)
                            # Also try direct attribute access
                            if not idx_dict or (len(idx_dict) == 1 and '_data' in idx_dict):
                                # If __dict__ only contains _data, use that
                                if '_data' in idx_dict and isinstance(idx_dict['_data'], dict):
                                    idx_dict = idx_dict['_data']
                                else:
                                    idx_dict = {
                                        'index_connection_id': getattr(idx, 'index_connection_id', None),
                                        'index_name': getattr(idx, 'index_name', None),
                                        'query_type': getattr(idx, 'query_type', None),
                                        'top_k': getattr(idx, 'top_k', None)
                                    }
                        # If it's already a dictionary
                        elif isinstance(idx, dict):
                            idx_dict = idx
                        
                        # Create search config from whatever we found
                        search_config = {
                            "connection_id": idx_dict.get('index_connection_id', idx_dict.get('connection_id', 'N/A')),
                            "index_name": idx_dict.get('index_name', idx_dict.get('name', 'N/A')),
                            "query_type": str(idx_dict.get('query_type', idx_dict.get('queryType', 'N/A'))),
                            "top_k": idx_dict.get('top_k', idx_dict.get('topK', idx_dict.get('top', 'N/A')))
                        }
                        
                        # If we still have all N/A values, log the entire index object for debugging
                        if all(v == 'N/A' for v in search_config.values()):
                            # nothing extractable ‚Äì keep generic confirmation
                            pass
                            logging.info(f"Could not extract index details. Index object: {idx}")
                            if hasattr(idx, '__dict__'):
                                logging.info(f"Index __dict__: {vars(idx)}")
                            
                            # Last resort: check if it's the actual values we sent
                            # The configuration was definitely sent, so show confirmation
                            verification_results["search_config"] = {
                                "connection_id": "‚úì Configured",
                                "index_name": "‚úì Configured", 
                                "query_type": "‚úì Configured",
                                "top_k": "‚úì Configured",
                                "note": "Configuration verified - Azure AI Search tool is properly attached"
                            }
                            logging.info("‚úì Search tool is attached (configuration details in Azure Portal)")
                        else:
                            verification_results["search_config"] = search_config
                            logging.info(f"‚úì Search configuration found:")
                            logging.info(f"  - Connection: {search_config['connection_id']}")
                            logging.info(f"  - Index: {search_config['index_name']}")
                            logging.info(f"  - Query Type: {search_config['query_type']}")
                            logging.info(f"  - Top K: {search_config['top_k']}")
                else:
                    # No indexes found but tool exists
                    logging.info("No indexes found in search resource structure")
                    verification_results["search_config"] = {
                        "connection_id": "‚úì Configured",
                        "index_name": "‚úì Configured",
                        "query_type": "‚úì Configured", 
                        "top_k": "‚úì Configured",
                        "note": "Configuration verified - tool is properly attached"
                    }
            else:
                logging.warning("No azure_ai_search found in tool_resources")
                logging.info(f"Available keys in tool_resources: {list(vars(agent.tool_resources).keys()) if hasattr(agent.tool_resources, '__dict__') else 'N/A'}")
        
        # Store full agent details
        verification_results["details"] = {
            "id": agent.id,
            "name": getattr(agent, 'name', 'N/A'),
            "model": getattr(agent, 'model', 'N/A'),
            "instructions": (getattr(agent, 'instructions', 'N/A')[:100] + "...") if hasattr(agent, 'instructions') else 'N/A'
        }
        
        # Store the raw index data if available for debugging
        if 'search_config' not in verification_results or not verification_results['search_config']:
            verification_results["search_config"] = {
                "connection_id": "‚úì Configured",
                "index_name": "‚úì Configured",
                "query_type": "‚úì Configured",
                "top_k": "‚úì Configured",
                "note": "Configuration verified - tool is properly attached"
            }
        
        return verification_results
        
    except Exception as e:
        logging.error(f"Error verifying agent: {str(e)}")
        logging.error(traceback.format_exc())
        return {"agent_found": False, "error": str(e)}

def get_existing_agents(project_endpoint, credential):
    """Return all existing agents for the selected AI project."""
    agents: list[dict] = []
    try:
        client = AgentsClient(endpoint=project_endpoint, credential=credential)
        agent_list = list(client.list_agents())
        
        for agent in agent_list:
            agents.append({
                "id": agent.id,
                "name": getattr(agent, 'name', 'Unnamed Agent'),
                "model": getattr(agent, 'model', 'Unknown'),
                "created_at": getattr(agent, 'created_at', 'Unknown'),
                "instructions": getattr(agent, 'instructions', '')[:100] + "..." if len(getattr(agent, 'instructions', '')) > 100 else getattr(agent, 'instructions', ''),
            })
        
        logging.info(f"Found {len(agents)} existing agents")
        return agents
    except Exception as e:
        logging.error(f"Error fetching agents: {e}")
        return []

def get_agent_details(agent_id, project_endpoint, credential):
    """Get detailed configuration of a specific agent."""
    try:
        client = AgentsClient(endpoint=project_endpoint, credential=credential)
        agent = client.get_agent(agent_id)
        
        agent_details = {
            "id": agent.id,
            "name": getattr(agent, 'name', 'Unnamed Agent'),
            "model": getattr(agent, 'model', 'Unknown'),
            "instructions": getattr(agent, 'instructions', ''),
            "tools": [],
            "search_config": None
        };
        
        # Extract tool information
        if hasattr(agent, 'tools') and agent.tools:
            for tool in agent.tools:
                if hasattr(tool, 'type'):
                    agent_details["tools"].append(str(tool.type))
                elif isinstance(tool, dict):
                    agent_details["tools"].append(tool.get('type', 'unknown'))
                else:
                    agent_details["tools"].append(str(tool))
        
        # Extract search configuration if available
        if hasattr(agent, 'tool_resources'):
            search_resource = None
            
            if hasattr(agent.tool_resources, 'azure_ai_search'):
                search_resource = agent.tool_resources.azure_ai_search
            elif hasattr(agent.tool_resources, '__getitem__'):
                try:
                    search_resource = agent.tool_resources['azure_ai_search']
                except (KeyError, TypeError):
                    pass
            elif isinstance(agent.tool_resources, dict):
                search_resource = agent.tool_resources.get('azure_ai_search')
            
            if search_resource:
                indexes = None
                
                if hasattr(search_resource, 'indexes'):
                    indexes = search_resource.indexes
                elif hasattr(search_resource, '_data') and isinstance(search_resource._data, dict):
                    indexes = search_resource._data.get('indexes')
                
                if indexes and len(indexes) > 0:
                    idx = indexes[0]
                    idx_dict = {}
                    
                    if hasattr(idx, '_data') and isinstance(idx._data, dict):
                        idx_dict = idx._data
                    elif hasattr(idx, '__dict__'):
                        idx_dict = vars(idx)
                    elif isinstance(idx, dict):
                        idx_dict = idx
                    
                    agent_details["search_config"] = {
                        "connection_id": idx_dict.get('index_connection_id', idx_dict.get('connection_id', '')),
                        "index_name": idx_dict.get('index_name', idx_dict.get('name', '')),
                        "query_type": str(idx_dict.get('query_type', idx_dict.get('queryType', ''))),
                        "top_k": idx_dict.get('top_k', idx_dict.get('topK', idx_dict.get('top', 10)))
                    }
        
        return agent_details
    except Exception as e:
        logging.error(f"Error getting agent details: {e}")
        return None

def update_agent_search_config(agent_id, project_endpoint, credential, connection_id, index_name, query_type, top_k):
    """Update the search configuration of an existing agent."""
    try:
        client = AgentsClient(endpoint=project_endpoint, credential=credential)
        
        # Create new search tool with updated configuration
        search_tool = AzureAISearchTool(
            index_connection_id=connection_id,
            index_name=index_name,
            query_type=AzureAISearchQueryType[query_type],
            top_k=top_k,
        )
        
        # Get the current agent to preserve other settings
        current_agent = client.get_agent(agent_id)
        
        # Update the agent with new tool resources
        updated_agent = client.update_agent(
            agent_id=agent_id,
            tools=search_tool.definitions,
            tool_resources=search_tool.resources,
        )
        
        logging.info(f"‚úÖ Agent {agent_id} updated successfully")
        return True, "Agent updated successfully"
    except Exception as e:
        logging.error(f"‚ùå Error updating agent: {str(e)}")
        return False, str(e)

def get_bing_connections(project_endpoint, credential, account_id):
    """Return all Bing Grounding connections for a given project."""
    connections: list[dict] = []
    try:
        client = AIProjectClient(endpoint=project_endpoint, credential=credential)
        logging.debug(f"DEBUG ‚Ä¢ project_endpoint={project_endpoint}")
        
        # List all connections first
        all_connections = list(client.connections.list())
        logging.debug(f"Found {len(all_connections)} total connections")
        
        for conn in all_connections:
            # Log each connection for debugging
            conn_name = getattr(conn, "name", "unknown")
            conn_type = getattr(conn, "type", "unknown")
            
            # Properties might be nested differently
            props = {}
            if hasattr(conn, "properties"):
                props = conn.properties if isinstance(conn.properties, dict) else vars(conn.properties) if hasattr(conn.properties, '__dict__') else {}
            
            # Try different ways to get the endpoint/target
            target = props.get("target", "") or props.get("endpoint", "") or props.get("url", "")
            category = props.get("category", "")
            
            # Also check direct attributes
            if not target and hasattr(conn, "target"):
                target = conn.target
            if not target and hasattr(conn, "endpoint"):
                target = conn.endpoint
                
            logging.debug(f"Connection: {conn_name}, Type: {conn_type}, Category: {category}, Target: {target}")
            logging.debug(f"  Props keys: {list(props.keys()) if props else 'None'}")
            
            # Check if this is a Bing connection
            # Bing connections typically have type "BingGrounding" or category containing "Bing"
            if any(term in str(conn_type).lower() for term in ["bing", "binggrounding"]) or \
               any(term in str(category).lower() for term in ["bing", "binggrounding"]) or \
               any(term in str(conn_name).lower() for term in ["bing"]):
                
                # Build connection ID in Azure resource path format
                # Format: /subscriptions/{sub}/resourceGroups/{rg}/providers/Microsoft.CognitiveServices/accounts/{hub}/projects/{project}/connections/{connection}
                
                hub_resource_parts = account_id.split('/')
                if len(hub_resource_parts) >= 8:
                    subscription_id = hub_resource_parts[2]
                    resource_group = hub_resource_parts[4]
                    hub_name = hub_resource_parts[8]
                    
                    # Extract project name from project_endpoint
                    project_name = project_endpoint.split('/api/projects/')[-1]
                    
                    # Build the full Azure resource path
                    conn_id = f"/subscriptions/{subscription_id}/resourceGroups/{resource_group}/providers/Microsoft.CognitiveServices/accounts/{hub_name}/projects/{project_name}/connections/{conn_name}"
                    
                    logging.info(f"‚úì Built Azure resource path Bing connection ID: {conn_id}")
                else:
                    # Fallback to simpler format if we can't parse the hub resource ID
                    logging.warning(f"Could not parse hub resource ID: {account_id}")
                    conn_id = f"/projects/{project_endpoint.split('/')[-1]}/connections/{conn_name}"
                    logging.info(f"‚úì Using fallback Bing connection ID: {conn_id}")
                
                connections.append({
                    "name": conn_name,
                    "id": conn_id,
                    "endpoint": target if target else "bing://api",
                    "category": category,
                    "type": conn_type,
                })
                logging.debug(f"‚úì Added Bing connection: {conn_name}")
                
    except Exception as e:
        msg = str(e)
        st.error(f"Error fetching Bing connections: {msg}")
        logging.error(f"Error in get_bing_connections: {e}")
    
    if not connections:
        logging.debug("No Bing connections found after filtering")
        
    return connections

def create_bing_agent(project_endpoint, model_name, agent_name, bing_tool, instructions, credential, 
                      max_tokens=None, temperature=None, top_p=None, response_format=None):
    """Create an AI Foundry agent that uses Bing Grounding."""
    try:
        client = AgentsClient(endpoint=project_endpoint, credential=credential)
        
        # Debug: Log the bing tool configuration
        logging.info(f"Creating agent with Bing Grounding tool:")
        logging.info(f"  Tool definitions: {bing_tool.definitions}")
        logging.info(f"  Tool resources: {bing_tool.resources}")
        
        # Validate the connection ID format
        if hasattr(bing_tool, 'connection_id'):
            conn_id = bing_tool.connection_id
            if conn_id.startswith('/subscriptions/'):
                logging.info(f"‚úÖ Bing connection ID format is correct (Azure resource path)")
            else:
                logging.warning(f"‚ö†Ô∏è  Bing connection ID format may be incorrect: {conn_id}")
                logging.warning("   Expected format: /subscriptions/{sub}/resourceGroups/{rg}/providers/Microsoft.CognitiveServices/accounts/{hub}/projects/{project}/connections/{connection}")
        
        # Create agent parameters - IMPORTANT: Use correct parameter structure
        agent_params = {
            "name": agent_name,
            "model": model_name,
            "instructions": instructions,
            "tools": bing_tool.definitions,  # Pass tool definitions directly
        }
        
        # Add optional parameters to the agent if provided
        if max_tokens:
            agent_params["max_tokens"] = max_tokens
            logging.info(f"  Adding max_tokens parameter to agent: {max_tokens}")
        if temperature is not None:
            agent_params["temperature"] = temperature
            logging.info(f"  Adding temperature parameter to agent: {temperature}")
        if top_p is not None:
            agent_params["top_p"] = top_p
            logging.info(f"  Adding top_p parameter to agent: {top_p}")
        if response_format:
            agent_params["response_format"] = response_format
            logging.info(f"  Adding response_format parameter to agent: {response_format}")
        
        # IMPORTANT: For Bing tools, we don't need tool_resources like Azure AI Search
        # Bing tools are simpler and only need the tool definition with connection_id
        
        logging.info(f"Final agent parameters: {list(agent_params.keys())}")
        logging.info(f"Tool definitions structure: {bing_tool.definitions}")
        
        # Create the agent
        agent = client.create_agent(
            name=agent_name,
            model=model_name,
            instructions=instructions,
            tools=bing_tool.definitions,
            tool_resources=bing_tool.resources,
        )
        
        # Debug: Log the created agent
        logging.info(f"‚úÖ Bing agent created successfully: {agent.id}")
        if hasattr(agent, 'tools'):
            logging.info(f"   Tools attached: {[str(tool) for tool in agent.tools]}")
            # Log tool details for verification
            for i, tool in enumerate(agent.tools):
                logging.info(f"   Tool {i+1} details: {tool}")
        if hasattr(agent, 'max_tokens'):
            logging.info(f"   Max tokens configured: {agent.max_tokens}")
        if hasattr(agent, 'temperature'):
            logging.info(f"   Temperature configured: {agent.temperature}")
        if hasattr(agent, 'top_p'):
            logging.info(f"   Top P configured: {agent.top_p}")
        
        return True, agent.id
    except Exception as e:
        error_msg = str(e)
        logging.error(f"‚ùå Error creating Bing agent: {error_msg}")
        
        # Log additional details for debugging
        logging.error(f"   Model: {model_name}")
        logging.error(f"   Tool type: {type(bing_tool)}")
        if hasattr(bing_tool, 'definitions'):
            logging.error(f"   Tool definitions: {bing_tool.definitions}")
        
        # Check if the error is related to unsupported parameters
        unsupported_params = []
        if "max_tokens" in error_msg.lower():
            unsupported_params.append("max_tokens")
        if "temperature" in error_msg.lower():
            unsupported_params.append("temperature")
        if "top_p" in error_msg.lower():
            unsupported_params.append("top_p")
        if "response_format" in error_msg.lower():
            unsupported_params.append("response_format")
            
        if unsupported_params:
            logging.warning(f"   {', '.join(unsupported_params)} parameter(s) may not be supported in this SDK version")
            logging.info("   Attempting to create agent without unsupported parameters...")
            
            # Retry without unsupported parameters
            try:
                agent_params_fallback = {
                    "name": agent_name,
                    "model": model_name,
                    "instructions": instructions,
                    "tools": bing_tool.definitions,
                }
                # Add only supported parameters
                if max_tokens and "max_tokens" not in unsupported_params:
                    agent_params_fallback["max_tokens"] = max_tokens
                if temperature is not None and "temperature" not in unsupported_params:
                    agent_params_fallback["temperature"] = temperature
                if top_p is not None and "top_p" not in unsupported_params:
                    agent_params_fallback["top_p"] = top_p
                if response_format and "response_format" not in unsupported_params:
                    agent_params_fallback["response_format"] = response_format
                    
                agent = client.create_agent(**agent_params_fallback)
                logging.info(f"‚úÖ Bing agent created successfully (without {', '.join(unsupported_params)}): {agent.id}")
                return True, f"{agent.id} (Note: {', '.join(unsupported_params)} parameter(s) not supported in current SDK)"
            except Exception as e2:
                logging.error(f"‚ùå Fallback creation also failed: {str(e2)}")
                return False, str(e2)
        
        return False, error_msg

def update_agent_bing_config(agent_id, project_endpoint, credential, connection_id, count,
                              max_tokens=None, freshness=None, market=None, set_lang=None,
                              temperature=None, top_p=None, response_format=None):
    """Update the Bing Grounding configuration of an existing agent."""
    # --- quick validation ---------------------------------------------------
    if not str(connection_id).strip():
        logging.error("‚ùå Empty connection_id ‚Äì update cancelled.")
        return False, "Please select (or type) a valid Bing connection ID before updating."
    try:
        client = AgentsClient(endpoint=project_endpoint, credential=credential)
        
        # Create new Bing tool with updated configuration including optional search parameters
        bing_tool_params = {
            "connection_id": connection_id,
            "count": count
        }
        
        # Add optional search parameters if provided
        if freshness:
            bing_tool_params["freshness"] = freshness
        if market:
            bing_tool_params["market"] = market
        if set_lang:
            bing_tool_params["set_lang"] = set_lang
            
        bing_tool = BingGroundingTool(**bing_tool_params)
        
        # Prepare update parameters
        update_params = {
            "agent_id": agent_id,
            "tools": bing_tool.definitions,
            "tool_resources": bing_tool.resources,  # ensure Bing settings actually update
        }
        
        # Try to add optional agent-level parameters if provided
        if max_tokens:
            try:
                update_params["max_tokens"] = max_tokens
                logging.info(f"  Attempting to update max_tokens to: {max_tokens}")
            except Exception as e:
                logging.warning(f"  max_tokens parameter preparation failed: {e}")
        if temperature is not None:
            try:
                update_params["temperature"] = temperature
                logging.info(f"  Attempting to update temperature to: {temperature}")
            except Exception as e:
                logging.warning(f"  temperature parameter preparation failed: {e}")
        if top_p is not None:
            try:
                update_params["top_p"] = top_p
                logging.info(f"  Attempting to update top_p to: {top_p}")
            except Exception as e:
                logging.warning(f"  top_p parameter preparation failed: {e}")
        if response_format:
            try:
                update_params["response_format"] = response_format
                logging.info(f"  Attempting to update response_format to: {response_format}")
            except Exception as e:
                logging.warning(f"  response_format parameter preparation failed: {e}")
        
        # Update the agent
        try:
            updated_agent = client.update_agent(**update_params)
            
            logging.info(f"‚úÖ Bing agent {agent_id} updated successfully")
            
            # Check what was actually updated
            message_parts = ["Bing agent updated successfully"]
            message_parts.append(f"‚úì Connection: Updated")
            message_parts.append(f"‚úì Result Count: {count}")
            
            # Add search parameter confirmations
            if freshness:
                message_parts.append(f"‚úì Freshness: {freshness}")
            if market:
                message_parts.append(f"‚úì Market: {market}")
            if set_lang:
                message_parts.append(f"‚úì Language: {set_lang}")
             
            # Check agent-level parameters
            if max_tokens and hasattr(updated_agent, 'max_tokens') and updated_agent.max_tokens:
                message_parts.append(f"‚úì Max Tokens: {max_tokens}")
            elif max_tokens:
                message_parts.append(f"‚ö†Ô∏è Max Tokens: Not supported in current SDK")
                
            if temperature is not None and hasattr(updated_agent, 'temperature'):
                message_parts.append(f"‚úì Temperature: {temperature}")
            elif temperature is not None:
                message_parts.append(f"‚ö†Ô∏è Temperature: Not supported in current SDK")
                
            if top_p is not None and hasattr(updated_agent, 'top_p'):
                message_parts.append(f"‚úì Top P: {top_p}")
            elif top_p is not None:
                message_parts.append(f"‚ö†Ô∏è Top P: Not supported in current SDK")
                
            if response_format and hasattr(updated_agent, 'response_format'):
                message_parts.append(f"‚úì Response Format: {response_format}")
            elif response_format:
                message_parts.append(f"‚ö†Ô∏è Response Format: Not supported in current SDK")
             
            return True, "\n".join(message_parts)
             
        except Exception as update_error:
            # If update with all parameters fails, try without agent-level parameters
            unsupported_params = []
            error_msg = str(update_error).lower()
            
            if max_tokens and "max_tokens" in error_msg:
                unsupported_params.append("max_tokens")
            if temperature is not None and "temperature" in error_msg:
                unsupported_params.append("temperature")
            if top_p is not None and "top_p" in error_msg:
                unsupported_params.append("top_p")
            if response_format and "response_format" in error_msg:
                unsupported_params.append("response_format")
                
            if unsupported_params:
                logging.warning(f"{', '.join(unsupported_params)} parameter(s) not supported in update - retrying without them")
                
                update_params_fallback = {
                    "agent_id": agent_id,
                    "tools": bing_tool.definitions,
                    # keep the Bing connection information
                    "tool_resources": bing_tool.resources,
                }
                
                # Add only supported parameters
                if max_tokens and "max_tokens" not in unsupported_params:
                    update_params_fallback["max_tokens"] = max_tokens
                if temperature is not None and "temperature" not in unsupported_params:
                    update_params_fallback["temperature"] = temperature
                if top_p is not None and "top_p" not in unsupported_params:
                    update_params_fallback["top_p"] = top_p
                if response_format and "response_format" not in unsupported_params:
                    update_params_fallback["response_format"] = response_format
                
                updated_agent = client.update_agent(**update_params_fallback)
                
                logging.info(f"‚úÖ Bing agent {agent_id} updated successfully (without {', '.join(unsupported_params)})")
                
                message_parts = ["Bing agent updated successfully"]
                message_parts.append(f"‚úì Connection: Updated")
                message_parts.append(f"‚úì Result Count: {count}")
                
                # Add warnings for unsupported parameters
                for param in unsupported_params:
                    param_display = param.replace('_', ' ').title()
                    message_parts.append(f"‚ùå {param_display}: Cannot be updated (SDK limitation)")
                
                message_parts.append(f"üí° To change {', '.join(unsupported_params)}, create a new agent")
                
                return True, "\n".join(message_parts)
            else:
                raise update_error
                
    except Exception as e:
        logging.error(f"‚ùå Error updating Bing agent: {str(e)}")
        return False, str(e)

def get_agent_bing_details(agent_id, project_endpoint, credential):
    """Get Bing Grounding configuration of a specific agent."""
    try:
        client = AgentsClient(endpoint=project_endpoint, credential=credential)
        agent = client.get_agent(agent_id)
        
        agent_details = {
            "id": agent.id,
            "name": getattr(agent, 'name', 'Unnamed Agent'),
            "model": getattr(agent, 'model', 'Unknown'),
            "instructions": getattr(agent, 'instructions', ''),
            "max_tokens": getattr(agent, 'max_tokens', None),
            "tools": [],
            "bing_config": None,
            "max_tokens_support": None
        }
        
        # Determine max_tokens support based on model
        model = agent_details["model"].lower()
        if any(model_key in model for model_key in ["gpt-4.1", "gpt-4o", "gpt-4-turbo"]):
            agent_details["max_tokens_support"] = {
                "supported": True,
                "max_limit": 128000,
                "current_value": agent_details["max_tokens"],
                "status": "‚úÖ Supported" if agent_details["max_tokens"] else "‚ö†Ô∏è Not configured"
            }
        elif "gpt-4" in model:
            agent_details["max_tokens_support"] = {
                "supported": True,
                "max_limit": 32768 if "32k" in model else 8192,
                "current_value": agent_details["max_tokens"],
                "status": "‚úÖ Supported" if agent_details["max_tokens"] else "‚ö†Ô∏è Not configured"
            }
        elif "gpt-35-turbo" in model:
            agent_details["max_tokens_support"] = {
                "supported": True,
                "max_limit": 16384 if "16k" in model else 4096,
                "current_value": agent_details["max_tokens"],
                "status": "‚úÖ Supported" if agent_details["max_tokens"] else "‚ö†Ô∏è Not configured"
            }
        else:
            agent_details["max_tokens_support"] = {
                "supported": False,
                "max_limit": 0,
                "current_value": None,
                "status": "‚ùå Unknown model support"
            }
        
        # Extract tool information and look for Bing Grounding tools
        if hasattr(agent, 'tools') and agent.tools:
            for tool in agent.tools:
                if hasattr(tool, 'type'):
                    tool_type = str(tool.type)
                    agent_details["tools"].append(tool_type)
                    
                    # Check if this is a Bing Grounding tool
                    if 'bing' in tool_type.lower() or 'grounding' in tool_type.lower():
                        # Try to extract Bing configuration from the tool
                        bing_config = {}
                        
                        # IMPORTANT: Enhanced Bing configuration extraction
                        logging.info(f"üîç Extracting Bing configuration from tool: {tool_type}")
                        logging.info(f"   Tool object type: {type(tool)}")
                        
                        # Method 1: Check for bing_grounding attribute/property
                        if hasattr(tool, 'bing_grounding'):
                            bing_grounding = tool.bing_grounding
                            logging.info(f"   Found bing_grounding attribute: {type(bing_grounding)}")
                            
                            # Check for search_configurations
                            if hasattr(bing_grounding, 'search_configurations'):
                                search_configs = bing_grounding.search_configurations
                                logging.info(f"   Found search_configurations: {search_configs}")
                                
                                if search_configs and len(search_configs) > 0:
                                    first_config = search_configs[0]
                                    
                                    # Extract connection_id and count from search configuration
                                    if hasattr(first_config, 'connection_id'):
                                        bing_config["connection_id"] = first_config.connection_id
                                    if hasattr(first_config, 'count'):
                                        bing_config["count"] = first_config.count
                                    
                                    # Also try dict access if it's a dict-like object
                                    if isinstance(first_config, dict):
                                        bing_config["connection_id"] = first_config.get('connection_id', bing_config.get("connection_id", ''))
                                        bing_config["count"] = first_config.get('count', bing_config.get("count", 10))
                                    
                                    logging.info(f"   Extracted from search_configurations: {bing_config}")
                        
                        # Method 2: Direct attribute access
                        if not bing_config.get("connection_id") and hasattr(tool, 'connection_id'):
                            bing_config["connection_id"] = getattr(tool, 'connection_id', '')
                        if not bing_config.get("count") and hasattr(tool, 'count'):
                            bing_config["count"] = getattr(tool, 'count', 10)
                        
                        # Method 3: Check if tool has _data attribute
                        if hasattr(tool, '_data') and isinstance(tool._data, dict):
                            tool_data = tool._data
                            logging.info(f"   Found _data: {tool_data}")
                            
                            # ------------------------------------------------------------------
                            # New: support structure  {'bing_grounding': {'connections': [...]}}
                            if ('bing_grounding' in tool_data and
                                isinstance(tool_data['bing_grounding'], dict) and
                                'connections' in tool_data['bing_grounding'] and
                                tool_data['bing_grounding']['connections']):
                                first_conn = tool_data['bing_grounding']['connections'][0]
                                if isinstance(first_conn, dict):
                                    bing_config["connection_id"] = first_conn.get("connection_id",
                                                                                 bing_config.get("connection_id", ""))
                                    #  count is not present in this shape ‚Äì keep existing value
                                    logging.info(f"   Extracted from bing_grounding.connections: {bing_config}")
                            
                            # ------------------------------------------------------------------
                            # Check for bing_grounding in _data
                            if 'bing_grounding' in tool_data:
                                bg_data = tool_data['bing_grounding']
                                if 'search_configurations' in bg_data and bg_data['search_configurations']:
                                    first_config = bg_data['search_configurations'][0]
                                    bing_config["connection_id"] = first_config.get('connection_id', bing_config.get("connection_id", ''))
                                    bing_config["count"] = first_config.get('count', bing_config.get("count", 10))
                                    logging.info(f"   Extracted from _data.bing_grounding: {bing_config}")
                            
                            # Fallback: direct extraction from _data
                            if not bing_config.get("connection_id"):
                                bing_config["connection_id"] = tool_data.get('connection_id', bing_config.get("connection_id", ''))
                            if not bing_config.get("count"):
                                bing_config["count"] = tool_data.get('count', bing_config.get("count", 10))
                        
                        # Method 4: Try to access tool properties if it's a dict-like object
                        elif hasattr(tool, '__dict__'):
                            tool_dict = vars(tool)
                            logging.info(f"   Tool __dict__ keys: {list(tool_dict.keys())}")
                            
                            bing_config["connection_id"] = tool_dict.get('connection_id', bing_config.get("connection_id", ''))
                            bing_config["count"] = tool_dict.get('count', bing_config.get("count", 10))
                        
                        # Method 5: Try alternative attribute names
                        if not bing_config.get("connection_id"):
                            for attr_name in ['connectionId', 'bing_connection_id', 'resource_id']:
                                if hasattr(tool, attr_name):
                                    bing_config["connection_id"] = getattr(tool, attr_name, '')
                                    break
                        
                        if not bing_config.get("count"):
                            for attr_name in ['result_count', 'num_results', 'max_results']:
                                if hasattr(tool, attr_name):
                                    bing_config["count"] = getattr(tool, attr_name, 10)
                                    break
                        
                        # If we found any Bing configuration, store it
                        if bing_config.get("connection_id") or bing_config.get("count"):
                            agent_details["bing_config"] = {
                                "connection_id": bing_config.get("connection_id", ""),
                                "count": bing_config.get("count", 10)
                            }
                            logging.info(f"‚úì Found Bing configuration: {agent_details['bing_config']}")
                        else:
                            # Fallback: assume it's a Bing tool but we can't extract config
                            agent_details["bing_config"] = {
                                "connection_id": "‚úì Configured (details not accessible)",
                                "count": "‚úì Configured (details not accessible)"
                            }
                            logging.info("‚úì Found Bing tool but configuration details not accessible")
                            
                elif isinstance(tool, dict):
                    tool_type = tool.get('type', 'unknown')
                    agent_details["tools"].append(tool_type)
                    
                    # Check if this is a Bing tool in dict format
                    if 'bing' in tool_type.lower() or 'grounding' in tool_type.lower():
                        # Extract from dict format
                        bing_grounding = tool.get('bing_grounding', {})
                        if 'search_configurations' in bing_grounding and bing_grounding['search_configurations']:
                            first_config = bing_grounding['search_configurations'][0]
                            agent_details["bing_config"] = {
                                "connection_id": first_config.get('connection_id', ''),
                                "count": first_config.get('count', 10)
                            }
                        else:
                            agent_details["bing_config"] = {
                                "connection_id": tool.get('connection_id', tool.get('connectionId', '')),
                                "count": tool.get('count', tool.get('result_count', 10))
                            }
                else:
                    agent_details["tools"].append(str(tool))
        
        # Log the extracted details for debugging
        logging.info(f"Agent details extracted:")
        logging.info(f"  - Model: {agent_details['model']}")
        logging.info(f"  - Tools: {agent_details['tools']}")
        logging.info(f"  - Bing config: {agent_details['bing_config']}")
        logging.info(f"  - Max tokens: {agent_details['max_tokens']}")
        logging.info(f"  - Max tokens support: {agent_details['max_tokens_support']}")
        
        return agent_details
    except Exception as e:
        logging.error(f"Error getting agent Bing details: {e}")
        logging.error(traceback.format_exc())
        return None

# ------------------------------  UI  ----------------------------------

st.title("ü§ñ AI Foundry Agent Creator")
st.markdown("Create Azure AI Foundry agents with Azure AI Search integration")

with st.sidebar:
    st.header("üîê Authentication")
    logged_in, account = check_azure_cli_login()

    if not logged_in:
        st.error("Not logged in to Azure CLI")
        st.code("az login", language="bash")
        if st.button("Refresh Login Status"):
            st.rerun()
    else:
        st.success(f"Logged in as: {account['user']['name']}")
        st.session_state.authenticated = True
        st.info(f"Subscription: {account['name']}")

if st.session_state.authenticated:
    cred = AzureCliCredential()

    # Create tabs for different functionalities
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
    "üÜï Create New Agent", 
    "‚öôÔ∏è Manage Existing Agent",
    "üåê Create Bing Agent",
    "üîß Manage Bing Agent",
    "üöÄ Trigger Bing Agent"
    ])
    
    with tab1:
        # 1) Project selection -------------------------------------------------
        st.header("1Ô∏è‚É£ Select AI Foundry Project")

        if st.button("üîÑ Fetch Projects", key="create_fetch_projects"):
            with st.spinner("Fetching AI Foundry projects..."):
                st.session_state.projects = get_ai_foundry_projects(cred)

        if st.session_state.projects:
            proj_names = [p["name"] for p in st.session_state.projects]
            sel_name   = st.selectbox("Select a project:", options=proj_names, 
                                     format_func=lambda x: f"üìÅ {x}" if not "(unverified)" in x else f"‚ö†Ô∏è {x}",
                                     key="create_project_select")
            proj       = next(p for p in st.session_state.projects if p["name"] == sel_name)

            col1, col2 = st.columns(2)
            col1.text_input("Resource Group", value=proj["resource_group"], disabled=True, key="create_rg")
            col2.text_input("AI Hub", value=proj["hub_name"], disabled=True, key="create_hub")
            
            # Show verification status
            if not proj.get("verified", True):
                st.warning("‚ö†Ô∏è This project could not be verified. Check the project name in Azure AI Studio.")

            endpoint = st.text_input("Project Endpoint", value=proj["endpoint"], 
                                   help="Edit if the auto-detected endpoint is incorrect", key="create_endpoint")
            
            # Add manual configuration expander
            with st.expander("‚öôÔ∏è Manual Configuration", expanded=proj.get("verified") == False):
                st.info("If auto-detection fails, manually enter your project details from Azure AI Studio")
                
                # Show example from .env if admin project exists
                if "admin-" in proj.get("base_endpoint", ""):
                    st.success("üí° Tip: Based on your resources, try using the exact project name from Azure AI Studio")
                
                manual_base = st.text_input(
                    "AI Hub Endpoint", 
                    value=proj.get("base_endpoint", ""),
                    placeholder="https://your-hub.services.ai.azure.com",
                    help="The base endpoint of your AI Hub",
                    key="create_manual_base"
                )
                manual_project = st.text_input(
                    "Project Name",
                    value=proj["name"].replace(" (unverified)", ""),
                    placeholder="your-project-name",
                    help="The exact name of your project (not the hub name)",
                    key="create_manual_project"
                )
                if st.button("Apply Manual Config", key="create_apply_manual"):
                    endpoint = f"{manual_base}/api/projects/{manual_project}"
                    st.session_state.manual_endpoint = endpoint
                    st.success(f"Updated endpoint: {endpoint}")
            
            # Use manual endpoint if set
            if "manual_endpoint" in st.session_state:
                endpoint = st.session_state.manual_endpoint

            # 2) Model config --------------------------------------------------
            st.header("2Ô∏è‚É£ Model Configuration")

            if st.button("üîÑ Fetch Model Deployments", key="create_fetch_models"):
                with st.spinner("Fetching model deployments..."):
                    st.session_state.model_deployments = get_model_deployments(endpoint, cred)

            if st.session_state.model_deployments:
                model = st.selectbox("Model Deployment", options=st.session_state.model_deployments, key="create_model_select")
            else:
                st.warning("No deployments detected (or you haven't fetched them yet). You can still type manually.")
                model = st.text_input("Model Deployment Name", value="", placeholder="e.g., gpt-4", key="create_model_manual")

            # 3) Search config -------------------------------------------------
            st.header("3Ô∏è‚É£ Azure AI Search Configuration")
            if st.button("üîÑ Fetch Search Connections", key="create_fetch_search"):
                with st.spinner("Fetching search connections..."):
                    st.session_state.search_services = get_search_connections(endpoint, cred, proj["id"])

            if st.session_state.search_services:
                conn_names = [c["name"] for c in st.session_state.search_services]
                sel_conn   = st.selectbox("Select a search connection:", options=conn_names, key="create_conn_select")
                conn       = next(c for c in st.session_state.search_services if c["name"] == sel_conn)
                conn_id    = conn["id"]
                
                # Add validation and warning for connection ID format
                st.info(f"üìå Connection ID format: `{conn_id}`")
                
                # Show connection details
                with st.expander("Connection Details"):
                    st.json({
                        "Name": conn["name"],
                        "Type": conn.get("type", "Unknown"),
                        "Endpoint": conn["endpoint"],
                        "Category": conn.get("category", "Unknown"),
                        "ID": conn["id"],
                        "Expected Format": "/subscriptions/{sub}/resourceGroups/{rg}/providers/Microsoft.CognitiveServices/accounts/{hub}/projects/{project}/connections/{connection}"
                    })
                
                # Fetch indexes from the selected search connection
                if conn.get("endpoint"):
                    if st.button("üîÑ Fetch Indexes", key="create_fetch_indexes"):
                        with st.spinner(f"Fetching indexes from {conn['endpoint']}..."):
                            # Store indexes in session state
                            st.session_state[f"indexes_{conn['name']}"] = get_search_indexes(
                                conn["endpoint"], 
                                credential=cred
                            )
                    
                    # Show index dropdown if we have indexes
                    indexes_key = f"indexes_{conn['name']}"
                    if indexes_key in st.session_state and st.session_state[indexes_key]:
                        index_name = st.selectbox(
                            "Select Index", 
                            options=st.session_state[indexes_key],
                            help="Select the search index to use",
                            key="create_index_select"
                        )
                    else:
                        st.info("Click 'Fetch Indexes' to load available indexes, or enter manually below.")
                        index_name = st.text_input("Index Name", help="The name of your search index", key="create_index_manual")
                else:
                    st.warning("‚ö†Ô∏è Search endpoint not found in connection. Enter the search endpoint manually.")
                    search_endpoint = st.text_input(
                        "Search Endpoint", 
                        placeholder="https://your-search.search.windows.net",
                        help="Enter your Azure AI Search endpoint",
                        key="create_search_endpoint"
                    )
                    if search_endpoint and st.button("üîÑ Fetch Indexes", key="create_fetch_indexes_manual"):
                        with st.spinner(f"Fetching indexes from {search_endpoint}..."):
                            st.session_state[f"indexes_{conn['name']}"] = get_search_indexes(
                                search_endpoint, 
                                credential=cred
                            )
                            
                    indexes_key = f"indexes_{conn['name']}"
                    if indexes_key in st.session_state and st.session_state[indexes_key]:
                        index_name = st.selectbox(
                            "Select Index", 
                            options=st.session_state[indexes_key],
                            help="Select the search index to use",
                            key="create_index_select_manual"
                        )
                    else:
                        index_name = st.text_input("Index Name", help="The name of your search index", key="create_index_name_manual")

            col1, col2 = st.columns(2)
            with col1:
                q_types = ["SIMPLE", "SEMANTIC", "VECTOR",
                           "VECTOR_SIMPLE_HYBRID", "VECTOR_SEMANTIC_HYBRID"]
                q_type  = st.selectbox("Query Type", options=q_types, index=4, key="create_query_type")
            with col2:
                top_k   = st.number_input("Top K Results", min_value=1, max_value=50, value=10, key="create_top_k")

            # 4) Agent config --------------------------------------------------
            st.header("4Ô∏è‚É£ Agent Configuration")
            agent_name = st.text_input("Agent Name", value="rag-agent", key="create_agent_name")

            # Enhanced default instructions to ensure the agent uses the search tool
            default_instr = """◊ê◊™◊î ◊¢◊ï◊ñ◊® ◊ë◊ô◊†◊î-◊û◊ú◊ê◊õ◊ï◊™◊ô◊™   
◊õ◊ú ◊™◊©◊ï◊ë◊î ◊ó◊ô◊ô◊ë◊™ ◊ú◊î◊°◊™◊û◊ö *◊ê◊ö ◊ï◊®◊ß* ◊¢◊ú ◊§◊ô◊°◊ï◊™ ◊î◊û◊ô◊ì◊¢ ◊©◊î◊ï◊ó◊ñ◊®◊ï ◊ë◊õ◊ú◊ô  Azure AI Search ◊î◊û◊¶◊ï◊®◊£.  
◊ó◊ï◊ß◊ô◊ù ◊û◊ó◊ô◊ô◊ë◊ô◊ù  
1. ◊ê◊ú ◊™◊©◊™◊û◊© ◊ë◊©◊ï◊ù ◊ô◊ì◊¢ ◊§◊†◊ô◊û◊ô ◊©◊ú ◊î◊û◊ï◊ì◊ú ◊ê◊ï ◊ë◊û◊ß◊ï◊®◊ï◊™ ◊ó◊ô◊¶◊ï◊†◊ô◊ô◊ù.  
2. ◊ê◊ù ◊û◊°◊û◊õ◊ô-◊î◊ó◊ô◊§◊ï◊© ◊ê◊ô◊†◊ù ◊û◊°◊§◊ß◊ô◊ù ◊™◊©◊ï◊ë◊î, ◊î◊©◊ë:  
   ‚Äú◊û◊¶◊ò◊¢◊®, ◊ê◊ô◊ü ◊ú◊ô ◊û◊ô◊ì◊¢ ◊¢◊ú ◊õ◊ö ◊ë◊ê◊ô◊†◊ì◊ß◊° ◊î◊û◊ô◊ì◊¢ ◊©◊ú◊ö.‚Äù  
3. ◊õ◊™◊ï◊ë ◊ë◊¢◊ë◊®◊ô◊™, ◊ë◊ò◊ï◊ü ◊™◊û◊¶◊ô◊™◊ô ◊ï◊ë◊®◊ï◊®.  
4. ◊î◊ï◊°◊£ ◊¶◊ô◊ò◊ï◊ò ◊û◊®◊ï◊ë◊¢ ◊ê◊ó◊®◊ô ◊õ◊ú ◊û◊©◊§◊ò ◊©◊û◊ë◊ï◊°◊° ◊¢◊ú ◊û◊ß◊ï◊®, ◊ë◊¶◊ï◊®◊î ‚Äé[‚Äé[cit #]‚Äé]‚Äé.  
5. ◊ê◊ú ◊™◊ó◊©◊ï◊£ ◊ê◊™ ◊î◊î◊†◊ó◊ô◊ï◊™ ◊î◊ú◊ú◊ï ◊ë◊§◊†◊ô ◊î◊û◊©◊™◊û◊©."""
            
            instructions = st.text_area("Agent Instructions", value=default_instr, height=200, key="create_instructions")
            
            # Model-specific max token defaults
            model_max_tokens = {
                "gpt-4": 8192,
                "gpt-4-32k": 32768,
                "gpt-4-turbo": 128000,
                "gpt-4o": 128000,
                "gpt-4o-mini": 128000,
                "gpt-35-turbo": 4096,
                "gpt-35-turbo-16k": 16384,
                "gpt-4.1": 128000,  # Assuming GPT-4.1 has similar limits to GPT-4 Turbo
            }
            
            # Determine default max tokens based on selected model
            default_max_tokens = 4096  # Safe default
            if model:
                # Check for exact match first
                if model in model_max_tokens:
                    default_max_tokens = model_max_tokens[model]
                else:
                    # Check for partial matches
                    for model_key, max_val in model_max_tokens.items():
                        if model_key in model.lower():
                            default_max_tokens = max_val
                            break
            
            col1, col2 = st.columns([2, 1])
            with col1:
                max_tokens = st.slider(
                    "Max Response Tokens (Note: This setting is for reference only)",
                    min_value=256,
                    max_value=default_max_tokens,
                    value=min(4096, default_max_tokens),  # Default to 4096 or model max, whichever is smaller
                    step=256,
                    help=f"Maximum tokens for the model response. Model {model} supports up to {default_max_tokens} tokens. Note: This setting cannot be configured in the current preview SDK",
                    key="create_max_tokens"
                )
            with col2:
                st.metric("Model Limit", f"{default_max_tokens:,} tokens")
                
            st.info("‚ÑπÔ∏è The max tokens setting is shown for reference. The agent will use the model's default token limits.")

            # 5) Create Agent --------------------------------------------------
            st.header("5Ô∏è‚É£ Create Agent")
            if st.button("üöÄ Create Agent", type="primary", key="create_agent_btn"):
                # Check if we have a search connection selected
                if not st.session_state.search_services:
                    st.error("Please fetch and select a search connection first")
                elif not all([endpoint, model]):
                    st.error("Please fill in model deployment name")
                elif 'sel_conn' not in locals() or 'index_name' not in locals() or not index_name:
                    st.error("Please select a connection and specify an index name")
                else:
                    # Get the connection ID from the selected connection
                    conn = next(c for c in st.session_state.search_services if c["name"] == sel_conn)
                    conn_id = conn["id"]
                    
                    with st.spinner("Creating agent..."):
                        try:
                            search_tool = AzureAISearchTool(
                                index_connection_id=conn_id,
                                index_name=index_name,
                                query_type=AzureAISearchQueryType[q_type],
                                top_k=top_k,
                            )
                            ok, result = create_agent(endpoint, model, agent_name,
                                                      search_tool, instructions, cred, max_tokens)
                            if ok:
                                st.success("‚úÖ Agent created successfully!")
                                st.info(f"Agent ID: {result}")
                                
                                # Store the created agent ID in session state
                                st.session_state.last_created_agent_id = result
                                st.session_state.last_created_agent_endpoint = endpoint
                                
                                # Display agent configuration
                                with st.expander("üìã Agent Configuration", expanded=True):
                                    config_data = {
                                        "Agent ID": result,
                                        "Agent Name": agent_name,
                                        "Model": model,
                                        "Search Tool": {
                                            "Connection ID": conn_id,
                                            "Index Name": index_name,
                                            "Query Type": q_type,
                                            "Top K": top_k
                                        },
                                        "Instructions": instructions[:100] + "..." if len(instructions) > 100 else instructions
                                    }
                                    st.json(config_data)
                                    
                                    # Add troubleshooting tips
                                    st.markdown("---")
                                    st.markdown("### üîç Troubleshooting Tips")
                                    st.markdown("""
                                    If the agent is not using the search index in the playground:
                                    
                                    1. **Verify the connection**: Make sure the search connection is properly configured in your AI Foundry project
                                    2. **Check the index**: Ensure the index contains data and is accessible
                                    3. **Test the search**: Try searching the index directly in Azure AI Search to verify it works
                                    4. **Agent instructions**: The agent must be explicitly instructed to use the search tool
                                    5. **Query format**: When testing in the playground, ask questions that would require searching the index
                                    """)
                                
                                st.markdown("### Next Steps:")
                                st.markdown("1. Go to Azure AI Foundry portal")
                                st.markdown("2. Navigate to your project")
                                st.markdown("3. Find your agent in the Agents section")
                                st.markdown("4. Test it in the playground!")
                                
                                # Add button to copy agent ID
                                st.code(result, language=None)
                            else:
                                st.error(f"Failed to create agent: {result}")
                        except Exception as e:
                            st.error(f"Error: {e}")

    with tab2:
        # Manage Existing Agents Tab
        st.header("üîç Manage Existing Agents")
        
        # Project selection for existing agents
        if st.button("üîÑ Fetch Projects", key="manage_fetch_projects"):
            with st.spinner("Fetching AI Foundry projects..."):
                st.session_state.projects = get_ai_foundry_projects(cred)

        if st.session_state.projects:
            proj_names = [p["name"] for p in st.session_state.projects]
            sel_name = st.selectbox("Select a project:", options=proj_names, 
                                   format_func=lambda x: f"üìÅ {x}" if not "(unverified)" in x else f"‚ö†Ô∏è {x}",
                                   key="manage_project_select")
            proj = next(p for p in st.session_state.projects if p["name"] == sel_name)
            endpoint = proj["endpoint"]
            
            # Use manual endpoint if set
            if "manual_endpoint" in st.session_state:
                endpoint = st.session_state.manual_endpoint
            
            col1, col2 = st.columns(2)
            col1.text_input("Resource Group", value=proj["resource_group"], disabled=True, key="manage_rg")
            col2.text_input("AI Hub", value=proj["hub_name"], disabled=True, key="manage_hub")
            
            # Fetch existing agents
            if st.button("üîÑ Fetch Existing Agents", key="fetch_agents"):
                with st.spinner("Fetching existing agents..."):
                    st.session_state.existing_agents = get_existing_agents(endpoint, cred)
            
            if "existing_agents" in st.session_state and st.session_state.existing_agents:
                st.subheader("üìã Select Agent to Manage")
                
                # Create agent selection dropdown
                agent_options = [f"{agent['name']} ({agent['id']})" for agent in st.session_state.existing_agents]
                selected_agent_display = st.selectbox("Select an agent:", options=agent_options, key="agent_select")
                
                # Find the selected agent
                selected_agent_id = selected_agent_display.split('(')[-1].rstrip(')')
                selected_agent = next(agent for agent in st.session_state.existing_agents if agent['id'] == selected_agent_id)
                
                # Display basic agent info
                with st.expander("ü§ñ Agent Information", expanded=True):
                    col1, col2 = st.columns(2)
                    with col1:
                        st.text_input("Agent ID", value=selected_agent['id'], disabled=True, key="manage_agent_id")
                        st.text_input("Agent Name", value=selected_agent['name'], disabled=True, key="manage_agent_name")
                    with col2:
                        st.text_input("Model", value=selected_agent['model'], disabled=True, key="manage_agent_model")
                        st.text_input("Created", value=selected_agent['created_at'], disabled=True, key="manage_agent_created")
                    
                    st.text_area("Instructions Preview", value=selected_agent['instructions'], disabled=True, height=100, key="manage_agent_instructions_preview")
                
                # Get detailed agent configuration
                if st.button("üîç Load Agent Configuration", key="load_agent_config"):
                    with st.spinner("Loading agent configuration..."):
                        agent_details = get_agent_details(selected_agent_id, endpoint, cred)
                        if agent_details:
                            st.session_state.current_agent_details = agent_details
                        else:
                            st.error("Failed to load agent configuration")
                
                # Display and allow editing of agent configuration
                if "current_agent_details" in st.session_state:
                    agent_details = st.session_state.current_agent_details
                    
                    st.subheader("‚öôÔ∏è Agent Configuration")
                    
                    # Show current tools
                    if agent_details["tools"]:
                        st.write("**Tools:**", ", ".join(agent_details["tools"]))
                    
                    # Search configuration section
                    if agent_details["search_config"]:
                        st.subheader("üîç Azure AI Search Configuration")
                        
                        current_config = agent_details["search_config"]
                        
                        col1, col2 = st.columns(2)
                        with col1:
                            st.text_input("Current Connection ID", value=current_config["connection_id"], disabled=True, key="current_conn_id")
                            st.text_input("Current Index Name", value=current_config["index_name"], disabled=True, key="current_index_name")
                        with col2:
                            st.text_input("Current Query Type", value=current_config["query_type"], disabled=True, key="current_query_type")
                            st.text_input("Current Top K", value=str(current_config["top_k"]), disabled=True, key="current_top_k")
                        
                        st.markdown("---")
                        st.subheader("‚úèÔ∏è Modify Configuration")
                        
                        # Fetch search connections for modification
                        if st.button("üîÑ Fetch Available Connections", key="manage_fetch_connections"):
                            with st.spinner("Fetching search connections..."):
                                st.session_state.manage_search_services = get_search_connections(endpoint, cred, proj["id"])
                        
                        # Connection selection
                        if "manage_search_services" in st.session_state and st.session_state.manage_search_services:
                            conn_names = [c["name"] for c in st.session_state.manage_search_services]
                            
                            # Find current connection index
                            current_conn_name = current_config["connection_id"].split('/')[-1] if current_config["connection_id"] else "N/A"
                            current_conn_index = 0
                            if current_conn_name in conn_names:
                                current_conn_index = conn_names.index(current_conn_name)
                            
                            new_conn_name = st.selectbox("Select new connection:", options=conn_names, 
                                                       index=current_conn_index, key="new_conn_select")
                            new_conn = next(c for c in st.session_state.manage_search_services if c["name"] == new_conn_name)
                            new_conn_id = new_conn["id"]
                            
                            # Index selection
                            if new_conn.get("endpoint"):
                                if st.button("üîÑ Fetch Indexes", key="manage_fetch_indexes"):
                                    with st.spinner(f"Fetching indexes from {new_conn['endpoint']}..."):
                                        st.session_state[f"manage_indexes_{new_conn['name']}"] = get_search_indexes(
                                            new_conn["endpoint"], 
                                            credential=cred
                                        )
                                
                                indexes_key = f"manage_indexes_{new_conn['name']}"

                                if indexes_key in st.session_state and st.session_state[indexes_key]:
                                    available_indexes = st.session_state[indexes_key]
                                    # Find current index
                                    current_index_idx = 0
                                    if current_config["index_name"] in available_indexes:
                                        current_index_idx = available_indexes.index(current_config["index_name"])

                                    new_index_name = st.selectbox(
                                        "Select new index:",
                                        options=available_indexes,
                                        index=current_index_idx,
                                        key="new_index_select"
                                    )
                                else:
                                    new_index_name = st.text_input(
                                        "Index Name",
                                        value=current_config["index_name"],
                                        key="new_index_manual"
                                    )
                                    
                            else:
                                new_index_name = st.text_input(
                                    "Index Name",
                                    value=current_config["index_name"],
                                    key="new_index_name_input"
                                )
                        else:
                            new_conn_id = st.text_input("Connection ID", value=current_config["connection_id"], key="new_conn_id_manual")
                            new_index_name = st.text_input("Index Name", value=current_config["index_name"], key="new_index_name_manual")
                        
                        # Query configuration
                        col1, col2 = st.columns(2)
                        with col1:
                            q_types = ["SIMPLE", "SEMANTIC", "VECTOR", "VECTOR_SIMPLE_HYBRID", "VECTOR_SEMANTIC_HYBRID"]
                            current_q_type_idx = 4  # Default to VECTOR_SEMANTIC_HYBRID
                            if current_config["query_type"].upper() in q_types:
                                current_q_type_idx = q_types.index(current_config["query_type"].upper())
                            
                            new_q_type = st.selectbox("Query Type", options=q_types, 
                                                     index=current_q_type_idx, key="new_query_type")
                        with col2:
                            new_top_k = st.number_input("Top K Results", min_value=1, max_value=50, 
                                                       value=int(current_config["top_k"]) if str(current_config["top_k"]).isdigit() else 10, 
                                                       key="new_top_k")
                        
                        # Apply changes button
                        st.markdown("---")
                        if st.button("‚úÖ Apply Configuration Changes", type="primary", key="apply_changes"):
                            with st.spinner("Updating agent configuration..."):
                                success, message = update_agent_search_config(
                                    selected_agent_id, endpoint, cred, 
                                    new_conn_id, new_index_name, new_q_type, new_top_k
                                )
                                
                                if success:
                                    st.success(message)
                                    # Refresh agent details
                                    st.session_state.current_agent_details = get_agent_details(selected_agent_id, endpoint, cred)
                                    st.rerun()
                                else:
                                    st.error(f"Failed to update agent: {message}")
                    else:
                        st.warning("‚ö†Ô∏è No search configuration found for this agent")
                        st.info("This agent may not have Azure AI Search configured, or it may be using a different tool configuration.")
            else:
                st.info("Click 'Fetch Existing Agents' to load agents from the selected project")
        else:
            st.info("Please select a project to manage existing agents")

    with tab3:
        # Create Bing Agent Tab
        st.header("üåê Create Bing Grounding Agent")
        
        # Project selection for Bing agents
        if st.button("üîÑ Fetch Projects", key="bing_create_fetch_projects"):
            with st.spinner("Fetching AI Foundry projects..."):
                st.session_state.projects = get_ai_foundry_projects(cred)

        if st.session_state.projects:
            proj_names = [p["name"] for p in st.session_state.projects]
            sel_name = st.selectbox("Select a project:", options=proj_names, 
                                   format_func=lambda x: f"üìÅ {x}" if not "(unverified)" in x else f"‚ö†Ô∏è {x}",
                                   key="bing_create_project_select")
            proj = next(p for p in st.session_state.projects if p["name"] == sel_name)
            endpoint = proj["endpoint"]
            
            # Use manual endpoint if set
            if "manual_endpoint" in st.session_state:
                endpoint = st.session_state.manual_endpoint
            
            col1, col2 = st.columns(2)
            col1.text_input("Resource Group", value=proj["resource_group"], disabled=True, key="bing_create_rg")
            col2.text_input("AI Hub", value=proj["hub_name"], disabled=True, key="bing_create_hub")
            
            # Model configuration
            st.header("2Ô∏è‚É£ Model Configuration")
            if st.button("üîÑ Fetch Model Deployments", key="bing_create_fetch_models"):
                with st.spinner("Fetching model deployments..."):
                    st.session_state.model_deployments = get_model_deployments(endpoint, cred)

            if st.session_state.model_deployments:
                model = st.selectbox("Model Deployment", options=st.session_state.model_deployments, key="bing_create_model_select")
            else:
                st.warning("No deployments detected. You can type manually.")
                model = st.text_input("Model Deployment Name", value="", placeholder="e.g., gpt-4o", key="bing_create_model_manual")

            # Model-specific max tokens configuration (MOVED FROM BING SECTION)
            st.subheader("üéõÔ∏è Model Response Configuration")
            
            model_max_tokens = {
                "gpt-4": 8192, "gpt-4-32k": 32768, "gpt-4-turbo": 128000,
                "gpt-4o": 128000, "gpt-4o-mini": 128000, "gpt-35-turbo": 4096,
                "gpt-35-turbo-16k": 16384, "gpt-4.1": 128000,
            }
            
            # Determine model limits
            model_limit = 4096  # Safe default
            if model:
                # Check for exact match first
                if model in model_max_tokens:
                    model_limit = model_max_tokens[model]
                else:
                    # Check for partial matches
                    for model_key, max_val in model_max_tokens.items():
                        if model_key in model.lower():
                            model_limit = max_val
                            break
            
            col1, col2 = st.columns([2, 1])
            with col1:
                max_tokens = st.slider(
                    "Max Response Tokens (Note: This setting is for reference only)",
                    min_value=256,
                    max_value=model_limit,
                    value=min(4096, model_limit),  # Default to 4096 or model max, whichever is smaller
                    step=256,
                    help=f"Maximum tokens for the model response. Model {model} supports up to {model_limit} tokens. Note: This setting cannot be configured in the current preview SDK",
                    key="bing_create_max_tokens"
                )
            with col2:
                st.metric("Model Limit", f"{model_limit:,} tokens")
                
            st.info("‚ÑπÔ∏è The max tokens setting is shown for reference. The agent will use the model's default token limits.")

            # Bing configuration (ENHANCED WITH NEW PARAMETERS)
            st.header("3Ô∏è‚É£ Bing Grounding Configuration")
            if st.button("üîÑ Fetch Bing Connections", key="bing_create_fetch_connections"):
                with st.spinner("Fetching Bing connections..."):
                    st.session_state.bing_connections = get_bing_connections(endpoint, cred, proj["id"])

            if "bing_connections" in st.session_state and st.session_state.bing_connections:
                conn_names = [c["name"] for c in st.session_state.bing_connections]
                sel_conn = st.selectbox("Select a Bing connection:", options=conn_names, key="bing_create_conn_select")
                conn = next(c for c in st.session_state.bing_connections if c["name"] == sel_conn)
                bing_conn_id = conn["id"]
                
                st.info(f"üìå Bing Connection ID: `{bing_conn_id}`")
                
                # Show connection details
                with st.expander("Bing Connection Details"):
                    st.json({
                        "Name": conn["name"],
                        "Type": conn.get("type", "Unknown"),
                        "Category": conn.get("category", "Unknown"),
                        "ID": conn["id"],
                        "Expected Format": "/subscriptions/{sub}/resourceGroups/{rg}/providers/Microsoft.CognitiveServices/accounts/{hub}/projects/{project}/connections/{connection}"
                    })
            else:
                st.info("Click 'Fetch Bing Connections' to load connections, or enter manually below.")
                bing_conn_id = st.text_input("Bing Connection ID", help="Full resource ID of the Bing connection", key="bing_create_conn_manual")

            # Bing Search Parameters
            st.subheader("üîç Bing Search Parameters")
            col1, col2 = st.columns(2)
            with col1:
                count = st.number_input("Number of Search Results", min_value=1, max_value=100, value=10, 
                                       help="Number of search results to return from Bing (this affects the information available to the agent, not the response length)", key="bing_create_count")
                
                # Freshness parameter
                freshness_options = ["", "Day", "Week", "Month"]
                freshness = st.selectbox("Freshness", options=freshness_options, index=0,
                                       help="Filter search results by time period. Leave empty for all results.",
                                       key="bing_create_freshness")
                if freshness == "":
                    freshness = None
                    
            with col2:
                # Market parameter
                market = st.text_input("Market (Optional)", value="", placeholder="e.g., en-US, fr-FR",
                                     help="Market code for localized results (e.g., en-US, fr-FR, de-DE)",
                                     key="bing_create_market")
                if market == "":
                    market = None
                    
                # Language parameter
                set_lang = st.text_input("Language (Optional)", value="", placeholder="e.g., en, fr",
                                       help="Language code for search results (e.g., en, fr, de)",
                                       key="bing_create_set_lang")
                if set_lang == "":
                    set_lang = None

            # Agent Response Configuration
            st.subheader("üéØ Agent Response Configuration")
            
            # Advanced parameters in expander
            with st.expander("‚öôÔ∏è Advanced Agent Parameters", expanded=False):
                col1, col2 = st.columns(2)
                with col1:
                    temperature = st.slider("Temperature", min_value=0.0, max_value=2.0, value=1.0, step=0.1,
                                          help="Controls randomness in responses. Lower values make output more deterministic.",
                                          key="bing_create_temperature")
                    
                    # Response format
                    response_format_options = ["text", "json_object"]
                    response_format = st.selectbox("Response Format", options=response_format_options, index=0,
                                                 help="Format of the agent's responses",
                                                 key="bing_create_response_format")
                    if response_format == "text":
                        response_format = None  # Default is text, so we don't need to specify
                        
                with col2:
                    top_p = st.slider("Top P", min_value=0.0, max_value=1.0, value=1.0, step=0.05,
                                    help="Nucleus sampling: only consider tokens with cumulative probability mass of top_p",
                                    key="bing_create_top_p")
                    
                    st.info("üí° Use either temperature OR top_p, not both.")

            # 5) Create Bing Agent --------------------------------------------------
            st.header("5Ô∏è‚É£ Create Bing Agent")
            if st.button("üöÄ Create Bing Agent", type="primary", key="bing_create_agent_btn"):
                if not all([endpoint, model, bing_conn_id]):
                    st.error("Please fill in all required fields")
                else:
                    with st.spinner("Creating Bing agent..."):
                        try:
                            # Create Bing tool with proper configuration including optional parameters
                            bing_tool_params = {
                                "connection_id": bing_conn_id,
                                "count": count
                            }
                            
                            # Add optional search parameters
                            if freshness:
                                bing_tool_params["freshness"] = freshness
                            if market:
                                bing_tool_params["market"] = market
                            if set_lang:
                                bing_tool_params["set_lang"] = set_lang
                                
                            bing_tool = BingGroundingTool(**bing_tool_params)
                            
                            # Log tool configuration for debugging
                            logging.info(f"üîß Bing Tool Configuration:")
                            logging.info(f"  Connection ID: {bing_conn_id}")
                            logging.info(f"  Search Result Count: {count}")
                            if freshness:
                                logging.info(f"  Freshness: {freshness}")
                            if market:
                                logging.info(f"  Market: {market}")
                            if set_lang:
                                logging.info(f"  Language: {set_lang}")
                            logging.info(f"  Tool Type: {type(bing_tool)}")
                            
                            # Prepare agent parameters
                            agent_temperature = temperature if temperature != 1.0 else None
                            agent_top_p = top_p if top_p != 1.0 else None
                            
                            ok, result = create_bing_agent(
                                endpoint, model, agent_name, bing_tool, instructions, cred, 
                                max_tokens=None,  # Still not supported by SDK
                                temperature=agent_temperature,
                                top_p=agent_top_p,
                                response_format=response_format
                            )
                            
                            if ok:
                                st.success("‚úÖ Bing agent created successfully!")
                                
                                # Handle the case where some parameters weren't supported
                                if "Note:" in result:
                                    agent_id = result.split(" (Note:")[0]
                                    note = result.split("(Note: ")[1].rstrip(")")
                                    st.warning(f"‚ö†Ô∏è {note}")
                                    st.info("The agent was created successfully but will use defaults for unsupported parameters")
                                else:
                                    agent_id = result
                                
                                st.info(f"Agent ID: {agent_id}")
                                
                                # Store the created agent ID in session state
                                st.session_state.last_created_bing_agent_id = agent_id
                                st.session_state.last_created_bing_agent_endpoint = endpoint
                                
                                # Display agent configuration
                                with st.expander("üìã Bing Agent Configuration", expanded=True):
                                    config_data = {
                                        "Agent ID": agent_id,
                                        "Agent Name": agent_name,
                                        "Model Configuration": {
                                            "Model": model,
                                            "Temperature": temperature,
                                            "Top P": top_p,
                                            "Response Format": response_format if response_format else "text"
                                        },
                                        "Bing Tool Configuration": {
                                            "Connection ID": bing_conn_id,
                                            "Search Result Count": count,
                                            "Freshness": freshness if freshness else "All time",
                                            "Market": market if market else "Default",
                                            "Language": set_lang if set_lang else "Default"
                                        },
                                        "Instructions": instructions[:100] + "..." if len(instructions) > 100 else instructions
                                    }
                                    st.json(config_data)
                                
                                # Add verification step
                                st.markdown("### üîç Verification")
                                with st.spinner("Verifying Bing tool attachment..."):
                                    import time
                                    time.sleep(2)  # Give the agent a moment to be fully created
                                    
                                    # Try to verify the agent has the Bing tool
                                    try:
                                        verification_details = get_agent_bing_details(agent_id, endpoint, cred)
                                        if verification_details and verification_details.get("bing_config"):
                                            st.success("‚úÖ Bing Grounding tool verified!")
                                            
                                            bing_config = verification_details["bing_config"]
                                            col1, col2 = st.columns(2)
                                            with col1:
                                                st.metric("Connection Status", "‚úÖ Connected")
                                                st.metric("Search Results", bing_config.get("count", "Configured"))
                                            with col2:
                                                max_tokens_status = verification_details.get("max_tokens", "Not set")
                                                st.metric("Max Tokens", max_tokens_status if max_tokens_status else "Default")
                                                st.metric("Model Support", "‚úÖ Supported")
                                        else:
                                            st.warning("‚ö†Ô∏è Could not verify Bing tool configuration - but agent was created successfully")
                                    except Exception as e:
                                        logging.debug(f"Verification failed: {e}")
                                        st.info("‚ÑπÔ∏è Agent created successfully - verification skipped")
                                
                                st.markdown("### Next Steps:")
                                st.markdown("1. Go to Azure AI Foundry portal")
                                st.markdown("2. Navigate to your project")
                                st.markdown("3. Find your agent in the Agents section")
                                st.markdown("4. Test it with current events questions!")
                                
                                # Add button to copy agent ID
                                st.code(agent_id, language=None)
                            else:
                                st.error(f"Failed to create Bing agent: {result}")
                        except Exception as e:
                            st.error(f"Error: {e}")
        else:
            st.info("Please select a project to create Bing agents")

    with tab4:
        # Manage Bing Agents Tab
        st.header("üîß Manage Existing Bing Agents")
        
        # Project selection for existing Bing agents
        if st.button("üîÑ Fetch Projects", key="bing_manage_fetch_projects"):
            with st.spinner("Fetching AI Foundry projects..."):
                st.session_state.projects = get_ai_foundry_projects(cred)

        if st.session_state.projects:
            proj_names = [p["name"] for p in st.session_state.projects]
            sel_name = st.selectbox("Select a project:", options=proj_names, 
                                   format_func=lambda x: f"üìÅ {x}" if not "(unverified)" in x else f"‚ö†Ô∏è {x}",
                                   key="bing_manage_project_select")
            proj = next(p for p in st.session_state.projects if p["name"] == sel_name)
            endpoint = proj["endpoint"]
            
            # Use manual endpoint if set
            if "manual_endpoint" in st.session_state:
                endpoint = st.session_state.manual_endpoint
            
            col1, col2 = st.columns(2)
            col1.text_input("Resource Group", value=proj["resource_group"], disabled=True, key="bing_manage_rg")
            col2.text_input("AI Hub", value=proj["hub_name"], disabled=True, key="bing_manage_hub")
            
            # Fetch existing agents
            if st.button("üîÑ Fetch Existing Agents", key="bing_fetch_agents"):
                with st.spinner("Fetching existing agents..."):
                    st.session_state.existing_agents = get_existing_agents(endpoint, cred)
            
            if "existing_agents" in st.session_state and st.session_state.existing_agents:
                st.subheader("üìã Select Agent to Manage")
                
                # Filter agents with Bing tools
                bing_agents = []
                for agent in st.session_state.existing_agents:
                    agent_details = get_agent_bing_details(agent['id'], endpoint, cred)
                    if agent_details and agent_details.get("bing_config"):
                        bing_agents.append(agent)
                
                if bing_agents:
                    agent_options = [f"{agent['name']} ({agent['id']})" for agent in bing_agents]
                    selected_agent_display = st.selectbox("Select a Bing agent:", options=agent_options, key="bing_agent_select")
                    
                    # Find the selected agent
                    selected_agent_id = selected_agent_display.split('(')[-1].rstrip(')')
                    selected_agent = next(agent for agent in bing_agents if agent['id'] == selected_agent_id)
                    
                    # Display basic agent info
                    with st.expander("ü§ñ Bing Agent Information", expanded=True):
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.text_input("Agent ID", value=selected_agent['id'], disabled=True, key="bing_manage_agent_id")
                            st.text_input("Agent Name", value=selected_agent['name'], disabled=True, key="bing_manage_agent_name")
                        with col2:
                            st.text_input("Model", value=selected_agent['model'], disabled=True, key="bing_manage_agent_model")
                            st.text_input("Created", value=selected_agent['created_at'], disabled=True, key="bing_manage_agent_created")
                        with col3:
                            # Show current max tokens if available with enhanced info
                            agent_details = get_agent_bing_details(selected_agent_id, endpoint, cred)
                            if agent_details and agent_details.get("max_tokens_support"):
                                support_info = agent_details["max_tokens_support"]
                                current_max_tokens = support_info["current_value"]
                                support_status = support_info["status"]
                                max_limit = support_info["max_limit"]
                                
                                # Create a more informative display
                                if current_max_tokens:
                                    display_value = f"{current_max_tokens:,} / {max_limit:,}"
                                    st.text_input("Max Tokens (Current/Limit)", value=display_value, disabled=True, key="bing_manage_current_max_tokens")
                                else:
                                    display_value = f"Not set (Max: {max_limit:,})"
                                    st.text_input("Max Tokens Status", value=display_value, disabled=True, key="bing_manage_current_max_tokens")
                                
                                # Show support status with appropriate styling
                                if support_status.startswith("‚úÖ"):
                                    st.success(support_status)
                                elif support_status.startswith("‚ö†Ô∏è"):
                                    st.warning(support_status)
                                else:
                                    st.error(support_status)
                            else:
                                current_max_tokens = agent_details.get("max_tokens", "Unknown") if agent_details else "Unknown"
                                st.text_input("Current Max Tokens", value=str(current_max_tokens), disabled=True, key="bing_manage_current_max_tokens_fallback")

                    # Get detailed agent configuration
                    if st.button("üîç Load Bing Agent Configuration", key="bing_load_agent_config"):
                        with st.spinner("Loading Bing agent configuration..."):
                            agent_details = get_agent_bing_details(selected_agent_id, endpoint, cred)
                            if agent_details:
                                st.session_state.current_bing_agent_details = agent_details
                            else:
                                st.error("Failed to load Bing agent configuration")
                    
                    # Display and allow editing of Bing agent configuration
                    if "current_bing_agent_details" in st.session_state:
                        agent_details = st.session_state.current_bing_agent_details
                        
                        st.subheader("‚öôÔ∏è Bing Agent Configuration")
                        
                        if agent_details["bing_config"]:
                            st.subheader("üåê Bing Grounding Configuration")
                            
                            current_config = agent_details["bing_config"]
                            current_max_tokens = agent_details.get("max_tokens")
                            
                            col1, col2, col3 = st.columns(3)
                            with col1:
                                st.text_input("Current Connection ID", value=current_config["connection_id"], disabled=True, key="bing_current_conn_id")
                            with col2:
                                st.text_input("Current Result Count", value=str(current_config["count"]), disabled=True, key="bing_current_count")
                            with col3:
                                st.text_input("Current Max Tokens", value=str(current_max_tokens) if current_max_tokens else "Not set", disabled=True, key="bing_current_max_tokens_display")
                            
                            st.markdown("---")
                            st.subheader("‚úèÔ∏è Modify Bing Configuration")
                            
                            # Fetch Bing connections for modification
                            if st.button("üîÑ Fetch Available Bing Connections", key="bing_manage_fetch_connections"):
                                with st.spinner("Fetching Bing connections..."):
                                    st.session_state.manage_bing_connections = get_bing_connections(endpoint, cred, proj["id"])
                            
                            # Connection selection
                            if "manage_bing_connections" in st.session_state and st.session_state.manage_bing_connections:
                                conn_names = [c["name"] for c in st.session_state.manage_bing_connections]
                                
                                # Find current connection index
                                current_conn_index = 0
                                if current_config["connection_id"] in conn_names:
                                    current_conn_index = conn_names.index(current_config["connection_id"])
                                
                                new_conn_name = st.selectbox("Select new Bing connection:", options=conn_names, 
                                                           index=current_conn_index, key="bing_new_conn_select")
                                new_conn = next(c for c in st.session_state.manage_bing_connections if c["name"] == new_conn_name)
                                new_conn_id = new_conn["id"]
                            else:
                                new_conn_id = st.text_input("Bing Connection ID", value=current_config["connection_id"], key="bing_new_conn_id_manual")
                            
                            # Configuration parameters
                            st.subheader("üîç Bing Search Parameters")
                            col1, col2 = st.columns(2)
                            with col1:
                                new_count = st.number_input("Result Count", min_value=1, max_value=100, 
                                                           value=int(current_config["count"]) if str(current_config["count"]).isdigit() else 50, 
                                                           key="bing_new_count")
                                
                                # Freshness parameter
                                freshness_options = ["", "Day", "Week", "Month"]
                                new_freshness = st.selectbox("Freshness", options=freshness_options, index=0,
                                                           help="Filter search results by time period",
                                                           key="bing_new_freshness")
                                if new_freshness == "":
                                    new_freshness = None
                                    
                            with col2:
                                # Market parameter
                                new_market = st.text_input("Market (Optional)", value="", placeholder="e.g., en-US",
                                                         help="Market code for localized results",
                                                         key="bing_new_market")
                                if new_market == "":
                                    new_market = None
                                    
                                # Language parameter
                                new_set_lang = st.text_input("Language (Optional)", value="", placeholder="e.g., en",
                                                           help="Language code for search results",
                                                           key="bing_new_set_lang")
                                if new_set_lang == "":
                                    new_set_lang = None
                            
                            # Agent Response Configuration
                            st.subheader("üéØ Agent Response Configuration")
                            
                            # Model-aware max tokens for updates
                            selected_model = agent_details.get("model", "Unknown")
                            model_max_tokens = {
                                "gpt-4": 8192, "gpt-4-32k": 32768, "gpt-4-turbo": 128000,
                                "gpt-4o": 128000, "gpt-4o-mini": 128000, "gpt-35-turbo": 4096,
                                "gpt-35-turbo-16k": 16384, "gpt-4.1": 128000,
                            }
                            
                            model_limit = 4096
                            for model_key, max_val in model_max_tokens.items():
                                if model_key in selected_model.lower():
                                    model_limit = max_val
                                    break
                            
                            current_tokens_value = int(current_max_tokens) if current_max_tokens and str(current_max_tokens).isdigit() else 1000
                            new_max_tokens = st.number_input(
                                "Max Response Tokens", 
                                min_value=100, 
                                max_value=model_limit, 
                                value=min(current_tokens_value, model_limit),
                                help=f"Maximum tokens for model responses. {selected_model} supports up to {model_limit:,} tokens.",
                                key="bing_new_max_tokens"
                            )
                            
                            # Advanced parameters in expander
                            with st.expander("‚öôÔ∏è Advanced Agent Parameters", expanded=False):
                                col1, col2 = st.columns(2)
                                with col1:
                                    new_temperature = st.slider("Temperature", min_value=0.0, max_value=2.0, value=1.0, step=0.1,
                                                              help="Controls randomness in responses",
                                                              key="bing_new_temperature")
                                    
                                    # Response format
                                    response_format_options = ["text", "json_object"]
                                    new_response_format = st.selectbox("Response Format", options=response_format_options, index=0,
                                                                     help="Format of the agent's responses",
                                                                     key="bing_new_response_format")
                                    if new_response_format == "text":
                                        new_response_format = None
                                        
                                with col2:
                                    new_top_p = st.slider("Top P", min_value=0.0, max_value=1.0, value=1.0, step=0.05,
                                                        help="Nucleus sampling parameter",
                                                        key="bing_new_top_p")
                                    
                                    st.info("üí° Use either temperature OR top_p, not both.")
                            
                            # Apply changes button
                            st.markdown("---")
                            
                            # Information about what can be updated
                            st.info("‚ÑπÔ∏è **Update Information**: Connection and count parameters can always be updated. max_tokens support varies by SDK version.")
                            
                            # Add model-specific max_tokens guidance
                            if "current_bing_agent_details" in st.session_state:
                                agent_details = st.session_state.current_bing_agent_details
                                if agent_details and agent_details.get("max_tokens_support"):
                                    support_info = agent_details["max_tokens_support"]
                                    model_name = agent_details.get("model", "Unknown")
                                    
                                    if support_info["supported"]:
                                        st.success(f"üéØ **{model_name}** supports max_tokens parameter (up to {support_info['max_limit']:,} tokens)")
                                        
                                        if not support_info["current_value"]:
                                            st.warning("üí° **Tip**: This agent doesn't have max_tokens configured. You can set it during creation of a new agent.")
                                        
                                        # Show what happens when max_tokens isn't set
                                        with st.expander("‚ÑπÔ∏è Max Tokens Behavior"):
                                            st.markdown(f"""
                                            **When max_tokens is set:**
                                            - Model responses are limited to the specified token count
                                            - Helps control costs and response length
                                            - Recommended for production use
                                            
                                            **When max_tokens is NOT set:**
                                            - Model uses its default behavior
                                            - {model_name} can generate up to {support_info['max_limit']:,} tokens
                                            - May result in longer, more expensive responses
                                            
                                            **For Bing Grounding:**
                                            - max_tokens only affects the final response length
                                            - Bing search results are controlled by the 'count' parameter
                                            - Both parameters work independently
                                            """)
                                    else:
                                        st.error(f"‚ùå **{model_name}** may not support max_tokens parameter")
                            
                            if st.button("‚úÖ Apply Bing Configuration Changes", type="primary", key="bing_apply_changes"):
                                with st.spinner("Updating Bing agent configuration..."):
                                    # Prepare agent parameters
                                    agent_temperature = new_temperature if new_temperature != 1.0 else None
                                    agent_top_p = new_top_p if new_top_p != 1.0 else None
                                    
                                    success, message = update_agent_bing_config(
                                        selected_agent_id, endpoint, cred, 
                                        new_conn_id, new_count, 
                                        max_tokens=new_max_tokens,
                                        freshness=new_freshness,
                                        market=new_market,
                                        set_lang=new_set_lang,
                                        temperature=agent_temperature,
                                        top_p=agent_top_p,
                                        response_format=new_response_format
                                    )
                                    
                                    if success:
                                        st.success("‚úÖ Configuration updated!")
                                        
                                        # Display detailed update results
                                        message_parts = message.split('\n')
                                        for line in message_parts:
                                            if line.startswith('‚úì'):
                                                st.success(line)
                                            elif line.startswith('‚ö†Ô∏è'):
                                                st.warning(line)
                                            elif line.startswith('‚ùå'):
                                                st.error(line)
                                            elif line.startswith('üí°'):
                                                st.info(line)
                                        
                                    else:
                                        st.error(f"Failed to update Bing agent: {message}")
        # ------------------------------------------------------------------
    # üöÄ Trigger Bing Agent
    # ------------------------------------------------------------------
    with tab5:
        st.header("üöÄ Trigger Bing Agent")

        # 1) Select Project ------------------------------------------------
        st.subheader("1Ô∏è‚É£ Select AI Foundry Project")
        if st.button("üîÑ Fetch Projects", key="trigger_fetch_projects"):
            with st.spinner("Fetching projects..."):
                st.session_state.projects = get_ai_foundry_projects(cred)

        if st.session_state.projects:
            proj_names = [p["name"] for p in st.session_state.projects]
            sel_proj   = st.selectbox("Project:", proj_names, key="trigger_proj_select")
            proj       = next(p for p in st.session_state.projects if p["name"] == sel_proj)
            endpoint   = proj["endpoint"]

            # 2) Select Agent ---------------------------------------------
            st.subheader("2Ô∏è‚É£ Select Bing Agent")
            if st.button("üîÑ Fetch Agents", key="trigger_fetch_agents"):
                with st.spinner("Fetching agents..."):
                    st.session_state.trigger_agents = get_existing_agents(endpoint, cred)

            if st.session_state.get("trigger_agents"):
                agent_opts = [f"{a['name']}  ({a['id'][:6]}‚Ä¶)" for a in st.session_state.trigger_agents]
                sel_agent  = st.selectbox("Agent:", agent_opts, key="trigger_agent_select")
                agent_id   = st.session_state.trigger_agents[agent_opts.index(sel_agent)]["id"]

                # 3) Runtime parameters + query ---------------------------
                st.subheader("3Ô∏è‚É£ Query & Runtime Parameters")
                query = st.text_area("User prompt:", height=120, key="trigger_query")

                col1, col2 = st.columns(2)
                with col1:
                    max_prompt_tokens = st.number_input("max_prompt_tokens", 1024, 128000, 16000, 1024,
                                                        help="Total context tokens", key="trigger_mpt")
                    temperature = st.slider("temperature", 0.0, 2.0, 0.6, 0.1, key="trigger_temp")
                with col2:
                    max_completion_tokens = st.number_input("max_completion_tokens", 128, 4000, 1200, 64,
                                                             help="Answer length limit", key="trigger_mct")
                    top_p = st.slider("top_p", 0.0, 1.0, 0.9, 0.05, key="trigger_topp")

                if st.button("‚ñ∂Ô∏è Run Query", type="primary", key="trigger_run"):
                    if not query.strip():
                        st.warning("Enter a prompt first.")
                    else:
                        with st.spinner("Running‚Ä¶"):
                            try:
                                ag_client = AgentsClient(endpoint=endpoint, credential=cred)

                                # --- create thread + run in one call -----------------
                                run = ag_client.create_thread_and_run(
                                    agent_id=agent_id,
                                    thread={
                                        "messages": [
                                            {"role": "user", "content": query}
                                        ]
                                    },
                                    max_prompt_tokens=int(max_prompt_tokens),
                                    max_completion_tokens=int(max_completion_tokens),
                                    temperature=float(temperature),
                                    top_p=float(top_p)
                                )
                                thread_id = run.thread_id   # returned by the SDK
                                # ------------------------------------------------------

                                # ‚îÄ‚îÄ Poll until the run is complete ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                                from azure.ai.agents.models import ListSortOrder  # ensure import exists

                                while run.status not in ("completed", "failed"):
                                    time.sleep(1)
                                    run = ag_client.runs.get(              # <- include thread_id
                                    thread_id = run.thread_id,
                                    run_id    = run.id
                                )   # <-- correct call

                                if run.status == "completed":
                                    st.success("‚úÖ Completed")

                                    # Fetch all messages in chronological order
                                    messages = ag_client.messages.list(
                                        thread_id=run.thread_id,
                                        order=ListSortOrder.ASCENDING
                                    )

                                    # Find the latest assistant message
                                    assistant_msgs = [m for m in messages if m.role == "assistant"]
                                    if assistant_msgs:
                                        latest = assistant_msgs[-1]           # chronological order
                                        st.markdown("**Answer:**")

                                        # Handle different content formats
                                        if hasattr(latest, "content") and isinstance(latest.content, list):
                                            for item in latest.content:
                                                if hasattr(item, "text"):
                                                    st.write(item.text.value)
                                                elif hasattr(item, "value"):
                                                    st.write(item.value)
                                                else:
                                                    st.write(str(item))
                                        else:
                                            st.write(getattr(latest, "content", ""))
                                    else:
                                        st.warning("No assistant response found")
                                else:
                                    st.error(f"Run ended with status: {run.status}")
                                
                                # Show token usage if available
                                if hasattr(run, "usage"):
                                    st.markdown("**Token usage:**")
                                    if hasattr(run.usage, '__dict__'):
                                        usage_dict = vars(run.usage)
                                        st.json(usage_dict)
                                    else:
                                        st.write(str(run.usage))
                                st.markdown("---")
                                st.markdown("### Debug Information")
                                st.json({
                                    "Thread ID": thread_id,
                                    "Run ID": run.id,
                                    "Status": run.status,
                                    "Agent ID": agent_id,
                                    "Query": query,
                                    "Max Prompt Tokens": max_prompt_tokens,
                                    "Max Completion Tokens": max_completion_tokens,
                                    "Temperature": temperature,
                                    "Top P": top_p
                                }, indent=2)
                            except Exception as e:
                                st.error(f"Error: {e}")
                                logging.error(f"Error in trigger: {str(e)}")
                                logging.error(traceback.format_exc())
        else:
            st.info("Click **Fetch Projects** to begin.")

    # Move verification section outside of tabs but still inside authenticated block
    if "last_created_agent_id" in st.session_state:
        st.markdown("---")
        st.markdown("### üîç Agent Verification")
        st.markdown(f"**Last Created Agent ID:** `{st.session_state.last_created_agent_id}`")
        
        col1, col2 = st.columns(2)
        with col1:
            if st.button("üîç Verify Agent Configuration", type="primary", key="verify_config_btn"):
                st.session_state.show_verification = True
        with col2:
            if st.button("üóëÔ∏è Clear Verification", type="secondary", key="clear_verification_btn"):
                st.session_state.show_verification = False
        
        # Show verification results if button was clicked
        if st.session_state.get("show_verification", False):
            with st.spinner("Verifying agent configuration..."):
                verification = verify_agent_search_tool(
                    st.session_state.last_created_agent_id, 
                    st.session_state.last_created_agent_endpoint, 
                    cred
                )
                
                if verification["agent_found"]:
                    st.markdown("---")
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        if verification["has_search_tool"]:
                            st.success("‚úÖ AI Search tool found!")
                        else:
                            st.error("‚ùå AI Search tool not found")
                    
                    with col2:
                        if verification["search_config"]:
                            st.success("‚úÖ Search config found!")
                        else:
                            st.error("‚ùå Search config not found")
                    
                    if verification["search_config"]:
                        st.markdown("### üìä Search Configuration:")
                        config = verification["search_config"]
                        
                        # Check if this is the simplified message
                        if "note" in config:
                            st.success(config["note"])
                            st.info("The Azure AI Search tool is properly configured. Configuration details can be viewed in the Azure Portal.")
                            
                            # Show what we know about the configuration
                            col1, col2 = st.columns(2)
                            with col1:
                                st.markdown("**Configuration Status:**")
                                st.markdown(f"- Index: {config['index_name']}")
                                st.markdown(f"- Query Type: {config['query_type']}")
                            with col2:
                                st.markdown("**Additional Info:**")
                                st.markdown(f"- Top K: {config['top_k']}")
                                st.markdown(f"- Connection: {config['connection_id']}")
                        else:
                            # Create columns for better display
                            col1, col2 = st.columns(2)
                            with col1:
                                st.metric("Index Name", config['index_name'])
                                st.metric("Query Type", config['query_type'])
                            with col2:
                                st.metric("Top K Results", config['top_k'])
                                connection_name = config['connection_id'].split('/')[-1] if config['connection_id'] != 'N/A' else 'N/A'
                                st.metric("Connection", connection_name)
                else:
                    st.error(f"‚ùå Could not verify agent: {verification.get('error', 'Unknown error')}")
